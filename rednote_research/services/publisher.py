"""å‘å¸ƒæœåŠ¡ - ç®¡ç†å°çº¢ä¹¦å‘å¸ƒæµç¨‹

åŠŸèƒ½ï¼š
1. å†…å®¹è½¬æ¢ï¼šæŠ¥å‘Š â†’ å°çº¢ä¹¦æ ¼å¼ï¼ˆæ ‡é¢˜â‰¤20å­—ï¼Œæ­£æ–‡â‰¤200å­—ï¼‰
2. è‰ç¨¿ç®¡ç†ï¼šåˆ›å»ºã€æ›´æ–°ã€è·å–ã€åˆ é™¤
3. å›¾ç‰‡ç”Ÿæˆåè°ƒï¼šå°é¢å›¾ + ç« èŠ‚å›¾
4. å‘å¸ƒæ‰§è¡Œï¼šè°ƒç”¨ xiaohongshu-mcp
"""

import os
import json
import uuid
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Optional, Callable
from pydantic import BaseModel


class PublishDraft(BaseModel):
    """å‘å¸ƒè‰ç¨¿"""
    id: str
    topic: str
    title: str  # â‰¤20å­—
    content: str  # â‰¤200å­—ï¼ˆå›¾æ–‡ç¬”è®°ï¼‰
    cover_image: Optional[str] = None
    section_images: list[str] = []
    tags: list[str] = []
    status: str = "draft"  # draft | generating | ready | publishing | published | failed
    created_at: str = ""
    updated_at: str = ""
    published_url: Optional[str] = None
    error: Optional[str] = None
    
    # åŸå§‹æ•°æ®ï¼ˆç”¨äºé‡æ–°ç”Ÿæˆï¼‰
    key_findings: list[str] = []
    sections: list[dict] = []


class PublishService:
    """å‘å¸ƒæœåŠ¡"""
    
    # è¡¨æƒ…ç¬¦å·æ˜ å°„
    EMOJI_MAP = {
        "æ¨è": "ğŸ’¡", "å¿…æ‰“å¡": "ğŸ“", "é¿é›·": "âš ï¸",
        "ç¾é£Ÿ": "ğŸœ", "æ—…æ¸¸": "âœˆï¸", "ä»·æ ¼": "ğŸ’°",
        "åˆ†äº«": "ğŸ’¬", "æ”¶è—": "â­", "æ”»ç•¥": "ğŸ“‹",
        "å¥½ç‰©": "âœ¨", "æ¢åº—": "ğŸ ", "ç©¿æ­": "ğŸ‘—"
    }
    
    def __init__(self, output_base_dir: str = None):
        """
        åˆå§‹åŒ–å‘å¸ƒæœåŠ¡
        
        Args:
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®ä¸‹çš„ output/publish
        """
        if output_base_dir:
            self.output_base_dir = output_base_dir
        else:
            # é»˜è®¤ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ output/publish
            project_dir = Path(__file__).parent.parent
            self.output_base_dir = str(project_dir / "output" / "publish")
        
        # è‰ç¨¿å­˜å‚¨ç›®å½•
        self.drafts_dir = os.path.join(self.output_base_dir, "drafts")
        Path(self.drafts_dir).mkdir(parents=True, exist_ok=True)
    
    # ===== å†…å®¹è½¬æ¢ =====
    
    def convert_to_xiaohongshu(
        self,
        topic: str,
        summary: str,
        key_findings: list[str],
        sections: list[dict],
        notes: list[dict] = None
    ) -> dict:
        """
        å°†ç ”ç©¶æŠ¥å‘Šè½¬æ¢ä¸ºå°çº¢ä¹¦æ ¼å¼
        
        Args:
            topic: ç ”ç©¶ä¸»é¢˜
            summary: æ‘˜è¦
            key_findings: å…³é”®å‘ç°
            sections: ç« èŠ‚åˆ—è¡¨
            notes: åŸå§‹ç¬”è®°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            {title, content, tags, key_findings, sections}
        """
        # 1. ç”Ÿæˆæ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰
        title = self._generate_title(topic, key_findings)
        
        # 2. ç”Ÿæˆæ­£æ–‡ï¼ˆâ‰¤200å­—ï¼‰
        content = self._generate_content(topic, summary, key_findings, sections)
        
        # 3. ç”Ÿæˆæ ‡ç­¾
        tags = self._generate_tags(topic, key_findings)
        
        return {
            "title": title,
            "content": content,
            "tags": tags,
            "key_findings": key_findings,
            "sections": sections
        }
    
    def _generate_title(self, topic: str, key_findings: list[str]) -> str:
        """
        ç”Ÿæˆæ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰
        
        æ ¼å¼ï¼š{emoji} {ä¸»é¢˜}ï½œ{äº®ç‚¹}
        ç¤ºä¾‹ï¼šâœ¨ ç©¿æ­åˆ†äº«ï½œæ˜¾ç˜¦åˆæ—¶é«¦
        """
        # ä¸»é¢˜ç›¸å…³emojiæ˜ å°„
        topic_emojis = {
            "ç©¿æ­": "ğŸ‘—", "ç¾é£Ÿ": "ğŸœ", "æ—…æ¸¸": "âœˆï¸", "æŠ¤è‚¤": "ğŸ’†",
            "ç¾å¦†": "ğŸ’„", "å¥èº«": "ğŸ’ª", "å®¶å±…": "ğŸ ", "æ•°ç ": "ğŸ“±",
            "è‚²å„¿": "ğŸ‘¶", "å® ç‰©": "ğŸ±", "æ‘„å½±": "ğŸ“¸", "èŒåœº": "ğŸ’¼"
        }
        
        # é€‰æ‹©emoji
        emoji = "âœ¨"
        for keyword, e in topic_emojis.items():
            if keyword in topic:
                emoji = e
                break
        
        # æå–ä¸»é¢˜æ ¸å¿ƒï¼ˆå»æ‰è¿‡é•¿çš„æè¿°ï¼‰
        core_topic = topic[:8] if len(topic) > 8 else topic
        
        # æå–äº®ç‚¹ï¼ˆä»å…³é”®å‘ç°ä¸­æå–ç²¾åï¼‰
        highlight = ""
        if key_findings:
            # æ¸…ç†å¹¶æå–å…³é”®è¯
            first_finding = key_findings[0]
            # å»é™¤"ç¬”è®°"ç­‰å­—çœ¼ï¼Œæå–æ ¸å¿ƒå†…å®¹
            cleaned = first_finding.replace("ç¬”è®°", "").replace("åˆ†æ", "").replace("å‘ç°", "").strip()
            max_len = 20 - len(emoji) - len(core_topic) - 2  # emoji + ç©ºæ ¼ + åˆ†éš”ç¬¦
            if max_len > 3 and cleaned:
                highlight = cleaned[:max_len]
        
        if highlight:
            title = f"{emoji}{core_topic}ï½œ{highlight}"
        else:
            title = f"{emoji}{core_topic}"
        
        return title[:20]
    
    def _generate_content(
        self, 
        topic: str, 
        summary: str, 
        key_findings: list[str],
        sections: list[dict]
    ) -> str:
        """
        ç”Ÿæˆæ­£æ–‡ï¼ˆâ‰¤200å­—ï¼‰
        
        ç»“æ„ï¼š
        ã€å¼€å¤´å¸å¼•ã€‘- 25å­—
        ã€æ ¸å¿ƒäº®ç‚¹ã€‘- 130å­—
        ã€äº’åŠ¨å¼•å¯¼ã€‘- 25å­—
        """
        lines = []
        
        # å¼€å¤´å¸å¼•è¯­ï¼ˆè‡ªç„¶æµç•…ï¼‰
        openers = [
            f"âœ¨ æ•´ç†äº†ä¸€ä»½è¶…å®ç”¨çš„{topic[:6]}ï¼Œç ä½ä¸äºï¼",
            f"ğŸ”¥ {topic[:8]}æ¥å•¦ï¼Œäº²æµ‹æœ‰æ•ˆï¼",
            f"ğŸ’¡ å…³äº{topic[:6]}ï¼Œè¿™äº›å¹²è´§åˆ†äº«ç»™ä½ ~",
            f"ğŸ“‹ {topic[:8]}å…¨æ”»ç•¥ï¼Œå»ºè®®æ”¶è—ï¼"
        ]
        import random
        intro = random.choice(openers)[:30]
        lines.append(intro)
        lines.append("")
        
        # æ ¸å¿ƒäº®ç‚¹ï¼ˆæ¸…ç†å’Œé‡ç»„å…³é”®å‘ç°ï¼‰
        if key_findings:
            lines.append("ğŸ“Œ åˆ’é‡ç‚¹ï¼š")
            for i, finding in enumerate(key_findings[:3]):
                # æ¸…ç†"ç¬”è®°"ç­‰å­—çœ¼ï¼Œæå–æ ¸å¿ƒå†…å®¹
                cleaned = self._clean_finding(finding)
                if cleaned:
                    emoji = self._get_emoji_for_content(cleaned)
                    # ç¡®ä¿è¯­å¥å®Œæ•´æµç•…
                    line = f"{emoji} {cleaned[:40]}"
                    lines.append(line)
        
        lines.append("")
        
        # äº’åŠ¨å¼•å¯¼ï¼ˆå¤šæ ·åŒ–ï¼‰
        outros = [
            "ğŸ’¬ è§‰å¾—æœ‰ç”¨å°±ç‚¹ä¸ªèµå§~",
            "â¤ï¸ æ”¶è—èµ·æ¥æ…¢æ…¢çœ‹ï¼",
            "ğŸ’­ ä½ ä»¬è¿˜æƒ³äº†è§£ä»€ä¹ˆï¼Ÿè¯„è®ºåŒºå‘Šè¯‰æˆ‘~",
            "ğŸ™‹ æœ‰é—®é¢˜è¯„è®ºåŒºäº¤æµå“¦ï¼"
        ]
        lines.append(random.choice(outros))
        
        content = "\n".join(lines)
        return content[:200]
    
    def _clean_finding(self, finding: str) -> str:
        """æ¸…ç†å…³é”®å‘ç°ï¼Œå»é™¤ä¸è‡ªç„¶çš„å­—çœ¼"""
        # éœ€è¦å»é™¤çš„è¯æ±‡
        remove_words = [
            "ç¬”è®°", "ç¬”è®°1", "ç¬”è®°2", "ç¬”è®°3", "ç¬”è®°4", "ç¬”è®°5",
            "åˆ†ææ˜¾ç¤º", "æ•°æ®è¡¨æ˜", "ç ”ç©¶å‘ç°", "ç»Ÿè®¡æ˜¾ç¤º",
            "æ ¹æ®", "é€šè¿‡", "æ€»ç»“", "å½’çº³"
        ]
        
        result = finding
        for word in remove_words:
            result = result.replace(word, "")
        
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹å’Œç©ºæ ¼
        result = result.strip()
        result = result.lstrip("ï¼Œ,ã€ï¼š:ï¼›;")
        result = result.strip()
        
        return result
    
    def _generate_tags(self, topic: str, key_findings: list[str]) -> list[str]:
        """ç”Ÿæˆæ ‡ç­¾ï¼ˆ3-5ä¸ªï¼‰"""
        tags = []
        
        # ä»ä¸»é¢˜æå–
        topic_words = topic.replace("ï½œ", " ").replace("ï¼Œ", " ").replace(",", " ").split()
        for word in topic_words[:2]:
            if len(word) >= 2:
                tags.append(word)
        
        # ä»å…³é”®å‘ç°æå–
        for finding in key_findings[:3]:
            words = finding.split()
            for word in words:
                if 2 <= len(word) <= 6 and word not in tags:
                    tags.append(word)
                    break
        
        # æ·»åŠ é€šç”¨æ ‡ç­¾
        common_tags = ["åˆ†äº«", "æ”»ç•¥", "æ¨è"]
        for tag in common_tags:
            if len(tags) < 5 and tag not in tags:
                tags.append(tag)
        
        return tags[:8]
    
    def _get_emoji_for_content(self, text: str) -> str:
        """æ ¹æ®å†…å®¹è·å–åˆé€‚çš„è¡¨æƒ…ç¬¦å·"""
        for keyword, emoji in self.EMOJI_MAP.items():
            if keyword in text:
                return emoji
        return "ğŸ’¡"
    
    # ===== è‰ç¨¿ç®¡ç† =====
    
    def create_draft(
        self,
        topic: str,
        summary: str,
        key_findings: list[str],
        sections: list[dict],
        notes: list[dict] = None
    ) -> PublishDraft:
        """åˆ›å»ºå‘å¸ƒè‰ç¨¿"""
        # ç”ŸæˆID
        draft_id = uuid.uuid4().hex
        now = datetime.now().isoformat()
        
        # è½¬æ¢å†…å®¹
        converted = self.convert_to_xiaohongshu(
            topic, summary, key_findings, sections, notes
        )
        
        # åˆ›å»ºè‰ç¨¿
        # åˆ›å»ºè‰ç¨¿ç›®å½•
        draft_dir = self._get_draft_dir(draft_id)
        images_dir = os.path.join(draft_dir, "images")
        Path(images_dir).mkdir(parents=True, exist_ok=True)
        
        # æå–å¹¶å¤åˆ¶å·²æœ‰å›¾ç‰‡
        import shutil
        existing_images = []
        if sections:
            for section in sections:
                if section.get("images"):
                    for img_path in section["images"]:
                        try:
                            # å¤„ç†æºè·¯å¾„
                            src_path = img_path
                            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•è§£æï¼ˆå‡è®¾ç›¸å¯¹äº output_base_dir æˆ–é¡¹ç›®æ ¹ç›®å½•ï¼‰
                            if not os.path.isabs(src_path):
                                # å°è¯•åœ¨ reports ç›®å½•ä¸‹å¯»æ‰¾
                                # è¿™é‡Œéœ€è¦ä¸€ç§æ›´å¯é çš„æ–¹å¼æ‰¾åˆ°æºæ–‡ä»¶ï¼Œç›®å‰å‡è®¾æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                                # ç®€å•èµ·è§ï¼Œå¦‚æœæ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»æ‰å¤åˆ¶
                                potential_paths = [
                                    src_path,
                                    os.path.join(self.output_base_dir, "..", src_path), # å°è¯•ç›¸å¯¹äº output ç›®å½•
                                    os.path.abspath(src_path)
                                ]
                                for p in potential_paths:
                                    if os.path.exists(p):
                                        src_path = p
                                        break
                            
                            if os.path.exists(src_path):
                                filename = os.path.basename(src_path)
                                dst_path = os.path.join(images_dir, filename)
                                shutil.copy2(src_path, dst_path)
                                # è®°å½•æ–°è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
                                existing_images.append(dst_path)
                        except Exception as e:
                            print(f"Copy image failed: {e}")
                            
        draft = PublishDraft(
            id=draft_id,
            topic=topic,
            title=converted["title"],
            content=converted["content"],
            tags=converted["tags"],
            key_findings=key_findings,
            sections=sections,
            section_images=existing_images[:9],  # æœ€å¤š9å¼ 
            status="draft",
            created_at=now,
            updated_at=now
        )
        
        # åˆ›å»ºè‰ç¨¿ç›®å½•
        draft_dir = self._get_draft_dir(draft_id)
        Path(draft_dir).mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è‰ç¨¿
        self._save_draft(draft)
        
        return draft
    
    def get_draft(self, draft_id: str) -> Optional[PublishDraft]:
        """è·å–è‰ç¨¿"""
        draft_path = os.path.join(self._get_draft_dir(draft_id), "draft.json")
        if not os.path.exists(draft_path):
            return None
        
        with open(draft_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        return PublishDraft(**data)
    
    def update_draft(self, draft_id: str, updates: dict) -> Optional[PublishDraft]:
        """æ›´æ–°è‰ç¨¿"""
        draft = self.get_draft(draft_id)
        if not draft:
            return None
        
        # æ›´æ–°å­—æ®µ
        for key, value in updates.items():
            if hasattr(draft, key):
                setattr(draft, key, value)
        
        draft.updated_at = datetime.now().isoformat()
        
        self._save_draft(draft)
        return draft
    
    def delete_draft(self, draft_id: str) -> bool:
        """åˆ é™¤è‰ç¨¿"""
        import shutil
        draft_dir = self._get_draft_dir(draft_id)
        if os.path.exists(draft_dir):
            shutil.rmtree(draft_dir)
            return True
        return False
    
    def list_drafts(self, limit: int = 20) -> list[PublishDraft]:
        """åˆ—å‡ºæ‰€æœ‰è‰ç¨¿"""
        drafts = []
        
        if not os.path.exists(self.drafts_dir):
            return drafts
        
        for draft_id in os.listdir(self.drafts_dir):
            draft = self.get_draft(draft_id)
            if draft:
                drafts.append(draft)
        
        # æŒ‰æ›´æ–°æ—¶é—´æ’åº
        drafts.sort(key=lambda d: d.updated_at, reverse=True)
        
        return drafts[:limit]
    
    def _get_draft_dir(self, draft_id: str) -> str:
        """è·å–è‰ç¨¿ç›®å½•"""
        return os.path.join(self.drafts_dir, draft_id)
    
    def _save_draft(self, draft: PublishDraft):
        """ä¿å­˜è‰ç¨¿"""
        draft_dir = self._get_draft_dir(draft.id)
        Path(draft_dir).mkdir(parents=True, exist_ok=True)
        
        draft_path = os.path.join(draft_dir, "draft.json")
        with open(draft_path, "w", encoding="utf-8") as f:
            json.dump(draft.model_dump(), f, ensure_ascii=False, indent=2)
    
    # ===== å›¾ç‰‡ç”Ÿæˆ =====
    
    async def generate_images(
        self,
        draft_id: str,
        generation_type: str = "all",  # all | cover | section
        on_log: Callable[[str], None] = None
    ) -> PublishDraft:
        """
        ä¸ºè‰ç¨¿ç”Ÿæˆå›¾ç‰‡ï¼ˆå°é¢+ç« èŠ‚å›¾ï¼‰
        
        Args:
            draft_id: è‰ç¨¿ID
            generation_type: ç”Ÿæˆç±»å‹ (all/cover/section)
            on_log: æ—¥å¿—å›è°ƒ
            
        Returns:
            æ›´æ–°åçš„è‰ç¨¿
        """
        from .image_generator import get_image_generator
        
        draft = self.get_draft(draft_id)
        if not draft:
            raise ValueError(f"è‰ç¨¿ä¸å­˜åœ¨: {draft_id}")
        
        # æ›´æ–°çŠ¶æ€
        draft = self.update_draft(draft_id, {"status": "generating"})
        
        generator = get_image_generator()
        draft_dir = self._get_draft_dir(draft_id)
        images_dir = os.path.join(draft_dir, "images")
        Path(images_dir).mkdir(parents=True, exist_ok=True)
        
        try:
            cover_path = draft.cover_image
            section_images = list(draft.section_images)
            
            # 1. ç”Ÿæˆå°é¢å›¾
            if generation_type in ["all", "cover"]:
                if on_log:
                    on_log("ğŸ“¸ å¼€å§‹ç”Ÿæˆå°é¢å›¾...")
                
                new_cover = await generator.generate_cover(
                    topic=draft.topic,
                    key_findings=draft.key_findings,
                    output_dir=images_dir,
                    on_log=on_log
                )
                
                if new_cover:
                    cover_path = new_cover
                    draft = self.update_draft(draft_id, {"cover_image": cover_path})
            
            # 2. ç”Ÿæˆç« èŠ‚å›¾
            if generation_type in ["all", "section"]:
                if on_log:
                    on_log("ğŸ“¸ å¼€å§‹ç”Ÿæˆç« èŠ‚é…å›¾...")
                
                new_sections = await generator.generate_section_images(
                    sections=draft.sections,
                    topic=draft.topic,
                    output_dir=images_dir,
                    max_images=5,
                    on_log=on_log
                )
                
                if new_sections:
                    # å¦‚æœæ˜¯å•ç‹¬ç”Ÿæˆç« èŠ‚å›¾ï¼Œè¿½åŠ è¿˜æ˜¯è¦†ç›–ï¼Ÿ
                    # ç°åœ¨çš„é€»è¾‘æ˜¯è¦†ç›–ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥è¿½åŠ ã€‚
                    # ä¸ºäº†ç®€å•ï¼Œå¦‚æœæ˜¯"section"ç±»å‹ï¼Œæˆ‘ä»¬è¿½åŠ ï¼Ÿ
                    # ä½†ç”¨æˆ·å¯èƒ½æƒ³é‡ç”Ÿæˆã€‚é€šå¸¸"ç”Ÿæˆ"æ„å‘³ç€é‡ç”Ÿæˆã€‚
                    # ä¿æŒè¦†ç›–é€»è¾‘ï¼Œå¦‚æœéœ€è¦è¿½åŠ ï¼Œéœ€å¦åŠ å‚æ•°ã€‚
                    # è¿™é‡Œä¿æŒè·ŸåŸæ¥ä¸€è‡´ï¼šgenerate_section_imagesè¿”å›æ•´ä¸ªåˆ—è¡¨ã€‚
                    section_images = new_sections
                    draft = self.update_draft(draft_id, {"section_images": section_images})
            
            # æ›´æ–°çŠ¶æ€
            draft = self.update_draft(draft_id, {"status": "ready"})
            
            if on_log:
                # ç»Ÿè®¡å½“å‰æ€»æ•°
                total_images = (1 if cover_path else 0) + len(section_images)
                on_log(f"âœ… å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼Œå½“å‰å…± {total_images} å¼ ")
            
            return draft
            
        except Exception as e:
            self.update_draft(draft_id, {
                "status": "draft",
                "error": str(e)
            })
            raise
    
    # ===== å‘å¸ƒæ‰§è¡Œ =====
    
    async def publish(
        self,
        draft_id: str,
        on_log: Callable[[str], None] = None
    ) -> PublishDraft:
        """
        å‘å¸ƒåˆ°å°çº¢ä¹¦
        
        Args:
            draft_id: è‰ç¨¿ID
            on_log: æ—¥å¿—å›è°ƒ
            
        Returns:
            æ›´æ–°åçš„è‰ç¨¿
        """
        from ..mcp.http_client import get_mcp_client
        
        draft = self.get_draft(draft_id)
        if not draft:
            raise ValueError(f"è‰ç¨¿ä¸å­˜åœ¨: {draft_id}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
        all_images = []
        if draft.cover_image:
            all_images.append(draft.cover_image)
        all_images.extend(draft.section_images)
        
        if not all_images:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾ç‰‡ï¼Œè¯·å…ˆç”Ÿæˆå›¾ç‰‡")
        
        # æ›´æ–°çŠ¶æ€
        draft = self.update_draft(draft_id, {"status": "publishing"})
        
        if on_log:
            on_log(f"ğŸš€ å¼€å§‹å‘å¸ƒåˆ°å°çº¢ä¹¦...")
            on_log(f"ğŸ“ æ ‡é¢˜: {draft.title}")
            on_log(f"ğŸ“¸ å›¾ç‰‡: {len(all_images)} å¼ ")
        
        try:
            # è½¬æ¢è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„ â†’ Docker å®¹å™¨è·¯å¾„ï¼‰
            docker_images = self._convert_to_docker_paths(all_images)
            
            if on_log:
                on_log(f"ğŸ“¦ è·¯å¾„è½¬æ¢å®Œæˆ")
            
            # è°ƒç”¨ MCP å‘å¸ƒ
            client = get_mcp_client()
            await client.connect()
            
            result = await client.publish_content(
                title=draft.title,
                content=draft.content,
                images=docker_images,
                tags=draft.tags
            )
            
            if result.get("success"):
                draft = self.update_draft(draft_id, {
                    "status": "published",
                    "published_url": result.get("url"),
                    "error": None
                })
                
                if on_log:
                    on_log(f"âœ… å‘å¸ƒæˆåŠŸï¼")
                    if result.get("url"):
                        on_log(f"ğŸ”— é“¾æ¥: {result.get('url')}")
            else:
                draft = self.update_draft(draft_id, {
                    "status": "failed",
                    "error": result.get("error", "å‘å¸ƒå¤±è´¥")
                })
                
                if on_log:
                    on_log(f"âŒ å‘å¸ƒå¤±è´¥: {result.get('error')}")
            
            return draft
            
        except Exception as e:
            self.update_draft(draft_id, {
                "status": "failed",
                "error": str(e)
            })
            
            if on_log:
                on_log(f"âŒ å‘å¸ƒé”™è¯¯: {str(e)}")
            
            raise
    
    def _convert_to_docker_paths(self, local_paths: list[str]) -> list[str]:
        """
        å°†æœ¬åœ°è·¯å¾„è½¬æ¢ä¸º Docker å®¹å™¨è·¯å¾„
        
        è§„åˆ™ï¼š
        - output ç›®å½•æŒ‚è½½åˆ° /app/output
        - ä¾‹ï¼š.../output/publish/... â†’ /app/output/publish/...
        """
        docker_paths = []
        
        # å®¹å™¨å†…è¾“å‡ºç›®å½•æŒ‚è½½ç‚¹
        mount_base = "/app/output"
        
        for path in local_paths:
            if not path:
                continue
            
            # å·²ç»æ˜¯ç›®æ ‡å®¹å™¨è·¯å¾„
            if path.startswith(mount_base):
                docker_paths.append(path)
                continue
            
            # æ˜¯ URL
            if path.startswith("http://") or path.startswith("https://"):
                docker_paths.append(path)
                continue
            
            # è·¯å¾„è½¬æ¢
            normalized = path.replace("\\", "/")
            
            # æå–ç›¸å¯¹è·¯å¾„
            # å‡è®¾è·¯å¾„æ ¼å¼ï¼š.../output/publish/...
            if "/output/" in normalized:
                rel_path = normalized.split("/output/", 1)[1]
                docker_path = f"{mount_base}/{rel_path}"
                docker_paths.append(docker_path)
            else:
                # æ— æ³•è½¬æ¢ï¼Œä¿æŒåŸæ ·ï¼ˆå¯èƒ½æ˜¯ç»å¯¹è·¯å¾„æˆ–å…¶ä»–æŒ‚è½½ï¼‰
                docker_paths.append(path)
        
        return docker_paths


# å…¨å±€å®ä¾‹
_publish_service: Optional[PublishService] = None


def get_publish_service() -> PublishService:
    """è·å–å‘å¸ƒæœåŠ¡å®ä¾‹"""
    global _publish_service
    if _publish_service is None:
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
        output_dir = os.getenv("PUBLISH_OUTPUT_DIR")
        _publish_service = PublishService(output_base_dir=output_dir)
    return _publish_service
