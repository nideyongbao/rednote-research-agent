"""FastAPI Webåº”ç”¨ - æä¾›SSEå®æ—¶ç ”ç©¶ç•Œé¢"""

import os
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from sse_starlette.sse import EventSourceResponse
from pydantic import BaseModel

from ..config import Config
from ..state import ResearchState
from ..mcp.rednote import RedNoteMCPClient
from ..agents.orchestrator import ResearchOrchestrator
from ..output.html_generator import HTMLReportGenerator
from ..services.settings import get_settings_service, Settings


# å…¨å±€çŠ¶æ€
_orchestrator: Optional[ResearchOrchestrator] = None
_mcp_client: Optional[RedNoteMCPClient] = None
_config: Optional[Config] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global _orchestrator, _mcp_client, _config
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    _config = Config.from_env()
    
    # MCPå®¢æˆ·ç«¯è·¯å¾„ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
    mcp_path = os.getenv("REDNOTE_MCP_PATH", "")
    if mcp_path:
        # æ”¯æŒç›¸å¯¹è·¯å¾„ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(mcp_path):
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆrednote_research çš„çˆ¶ç›®å½•ï¼‰
            project_root = Path(__file__).parent.parent.parent
            mcp_path = str((project_root / mcp_path).resolve())
        _mcp_client = RedNoteMCPClient(mcp_path)
        _orchestrator = ResearchOrchestrator(_config, _mcp_client)
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    if _mcp_client:
        await _mcp_client.disconnect()


def create_app() -> FastAPI:
    """åˆ›å»ºFastAPIåº”ç”¨"""
    app = FastAPI(
        title="RedNote Research Agent",
        description="åŸºäºMCPçš„å°çº¢ä¹¦æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“",
        version="0.1.0",
        lifespan=lifespan
    )
    
    # æŒ‚è½½é™æ€æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼šå‰ç«¯æ„å»ºäº§ç‰©ï¼‰
    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        assets_dir = static_dir / "assets"
        if assets_dir.exists():
            app.mount("/assets", StaticFiles(directory=str(assets_dir)), name="assets")
    
    # æ³¨æ„ï¼šSPA catch-all è·¯ç”±åœ¨æ–‡ä»¶æœ«å°¾æ³¨å†Œï¼Œç¡®ä¿ API è·¯ç”±ä¼˜å…ˆåŒ¹é…
    return app


app = create_app()



@app.get("/api/research")
async def research_stream(topic: str = Query(None), task: str = Query(None, min_length=2)):
    """
    SSEæµå¼è¿”å›ç ”ç©¶è¿›åº¦å’Œç»“æœ
    
    äº‹ä»¶ç±»å‹:
    - message: JSONæ ¼å¼çš„æ¶ˆæ¯ï¼ŒåŒ…å« type, level, message, stage, stats ç­‰å­—æ®µ
    
    æ¶ˆæ¯ç±»å‹(type):
    - log: è¿›åº¦æ—¥å¿—
    - stage: é˜¶æ®µåˆ‡æ¢
    - stats: ç»Ÿè®¡æ›´æ–°
    - complete: å®Œæˆä¿¡å·
    - error: é”™è¯¯ä¿¡æ¯
    """
    import json
    global _orchestrator, _mcp_client, _config
    
    # å…¼å®¹æ–°æ—§å‚æ•°å
    research_topic = topic or task
    if not research_topic or len(research_topic) < 2:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æœ‰æ•ˆçš„ç ”ç©¶ä¸»é¢˜")
    
    # åˆ›å»ºå†å²è®°å½•
    from ..services.history import get_history_service
    history_service = get_history_service()
    record = history_service.create(research_topic)
    record_id = record.id
    
    async def event_generator():
        stats = {"notesFound": 0, "contentsAnalyzed": 0, "insightsExtracted": 0}
        final_status = "failed"  # é»˜è®¤å¤±è´¥ï¼ŒæˆåŠŸæ—¶æ›´æ–°
        
        def make_msg(msg_type: str, **kwargs) -> dict:
            """ç”Ÿæˆæ ‡å‡†æ¶ˆæ¯æ ¼å¼"""
            return {"data": json.dumps({"type": msg_type, "recordId": record_id, **kwargs}, ensure_ascii=False)}
        
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            history_service.update(record_id, {"status": "running"})
            
            yield make_msg("log", level="info", message=f"ğŸš€ å¼€å§‹ç ”ç©¶: {research_topic}")
            yield make_msg("stage", stage="planning")
            
            # æ£€æŸ¥MCPå®¢æˆ·ç«¯
            if not _mcp_client:
                yield make_msg("log", level="warning", message="MCPå®¢æˆ·ç«¯æœªé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                # æ¨¡æ‹Ÿç ”ç©¶æµç¨‹
                yield make_msg("log", level="info", message="ğŸ“‹ [Planner] åˆ†æç ”ç©¶ä¸»é¢˜...")
                await asyncio.sleep(1)
                yield make_msg("log", level="success", message="ğŸ“‹ [Planner] ç”Ÿæˆäº† 3 ä¸ªæœç´¢å…³é”®è¯")
                
                yield make_msg("stage", stage="searching")
                yield make_msg("log", level="info", message="ğŸ” [Searcher] å¼€å§‹æœç´¢ç¬”è®°...")
                await asyncio.sleep(1)
                stats["notesFound"] = 15
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ” [Searcher] æ”¶é›†äº† {stats['notesFound']} ç¯‡ç¬”è®°")
                
                yield make_msg("stage", stage="analyzing")
                yield make_msg("log", level="info", message="ğŸ§  [Analyzer] åˆ†ææ•°æ®ä¸­...")
                await asyncio.sleep(1)
                stats["contentsAnalyzed"] = 15
                stats["insightsExtracted"] = 8
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ§  [Analyzer] æå–äº† {stats['insightsExtracted']} æ¡æ ¸å¿ƒå‘ç°")
                
                yield make_msg("stage", stage="generating")
                yield make_msg("log", level="info", message="ğŸ“ [Writer] ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...")
                await asyncio.sleep(1)
                yield make_msg("log", level="success", message="âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                yield make_msg("complete")
                return
            
            # è¿æ¥MCP
            yield make_msg("log", level="info", message="ğŸ“¡ è¿æ¥å°çº¢ä¹¦MCPæœåŠ¡...")
            await _mcp_client.connect()
            yield make_msg("log", level="success", message="âœ… MCPè¿æ¥æˆåŠŸ")
            
            # åˆ›å»ºç¼–æ’å™¨
            orchestrator = ResearchOrchestrator(_config, _mcp_client)
            
            # æ‰§è¡Œç ”ç©¶
            state = ResearchState(task=research_topic)
            
            # é˜¶æ®µ1: è§„åˆ’
            yield make_msg("progress", percent=10)
            yield make_msg("log", level="info", message="ğŸ“‹ [Planner] åˆ†æç ”ç©¶ä¸»é¢˜...")
            state = await orchestrator.planner.run(state)
            if state.plan:
                yield make_msg("log", level="success", message=f"ğŸ“‹ [Planner] ç”Ÿæˆäº† {len(state.plan.keywords)} ä¸ªæœç´¢å…³é”®è¯")
                yield make_msg("log", level="info", message=f"ğŸ’¡ ç†è§£: {state.plan.understanding}")
                yield make_msg("log", level="info", message=f"ğŸ“Š ç»´åº¦: {', '.join(state.plan.dimensions)}")
                for kw in state.plan.keywords:
                    yield make_msg("log", level="info", message=f"  - {kw}")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ1ç»Ÿè®¡] å…³é”®è¯: {len(state.plan.keywords)}ä¸ª | ç»´åº¦: {len(state.plan.dimensions)}ä¸ª | LLMè°ƒç”¨: 1æ¬¡")
            
            # é˜¶æ®µ2: æœç´¢
            yield make_msg("stage", stage="searching")
            yield make_msg("progress", percent=25)
            yield make_msg("log", level="info", message="ğŸ” [Searcher] å¼€å§‹æœç´¢ç¬”è®°...")
            
            # æ”¶é›†æœç´¢æ—¥å¿—ç”¨äºå‰ç«¯æ˜¾ç¤º
            search_logs = []
            def capture_log(msg):
                search_logs.append(msg)
            
            state = await orchestrator.searcher.run(state, on_log=capture_log)
            
            # è¾“å‡ºæ¯ä¸ªå…³é”®è¯çš„æœç´¢ç»“æœåˆ°å‰ç«¯
            for log in search_logs:
                yield make_msg("log", level="info", message=f"  {log}")
            
            stats["notesFound"] = len(state.documents)
            yield make_msg("stats", stats=stats)
            yield make_msg("log", level="success", message=f"ğŸ” [Searcher] æ”¶é›†äº† {stats['notesFound']} ç¯‡ç¬”è®°")
            
            # è®¡ç®—å¹¶è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
            total_images = sum(len(note.detail.images) for note in state.documents if note.detail.images)
            total_text_length = sum(len(note.detail.content or "") for note in state.documents)
            avg_text_length = total_text_length // len(state.documents) if state.documents else 0
            yield make_msg("log", level="info", message=f"ğŸ“Š [ç»Ÿè®¡] å…± {total_images} å¼ å›¾ç‰‡ï¼Œæ€»æ–‡æœ¬ {total_text_length} å­—ï¼Œå¹³å‡æ¯ç¯‡ {avg_text_length} å­—")
            
            # é˜¶æ®µ3: åˆ†æ
            yield make_msg("stage", stage="analyzing")
            yield make_msg("progress", percent=45)
            yield make_msg("log", level="info", message="ğŸ§  [Analyzer] åˆ†ææ•°æ®ä¸­...")
            state = await orchestrator.analyzer.run(state)
            stats["contentsAnalyzed"] = len(state.documents)
            if state.insights:
                findings = state.insights.get("key_findings", [])
                stats["insightsExtracted"] = len(findings)
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ§  [Analyzer] æå–äº† {stats['insightsExtracted']} æ¡æ ¸å¿ƒå‘ç°")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ3ç»Ÿè®¡] åˆ†æç¬”è®°: {len(state.documents)}ç¯‡ | æå–å‘ç°: {stats['insightsExtracted']}æ¡ | LLMè°ƒç”¨: 1æ¬¡")
            
            # é˜¶æ®µ4: å›¾ç‰‡VLMåˆ†æï¼ˆæå‰åˆ°å¤§çº²ä¹‹å‰ï¼‰
            yield make_msg("progress", percent=55)
            yield make_msg("log", level="info", message="ğŸ–¼ï¸ [ImageAnalyzer] VLMåˆ†æå›¾ç‰‡...")
            
            from ..output.image_analyzer import ImageAnalyzer
            image_analyzer = ImageAnalyzer()
            
            image_logs = []
            def capture_image_log(msg):
                image_logs.append(msg)
            
            try:
                state, img_stats = await image_analyzer.analyze(state, on_log=capture_image_log)
                
                # è¾“å‡ºè¯¦ç»†æ—¥å¿—
                for log in image_logs:
                    yield make_msg("log", level="info", message=f"  {log}")
                
                analyzed_count = len(state.image_analyses)
                usable_count = sum(1 for r in state.image_analyses.values() if r.should_use)
                vlm_calls = img_stats.get("vlm_calls", 0)
                yield make_msg("log", level="success", message=f"ğŸ–¼ï¸ [ImageAnalyzer] åˆ†æäº† {analyzed_count} å¼ å›¾ç‰‡ï¼Œ{usable_count} å¼ å¯ç”¨")
                
                # ç»Ÿè®¡åˆ†ç±»
                categories = {}
                for r in state.image_analyses.values():
                    cat = r.category or "æœªåˆ†ç±»"
                    categories[cat] = categories.get(cat, 0) + 1
                cat_str = ", ".join(f"{k}:{v}" for k, v in categories.items())
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ4ç»Ÿè®¡] åˆ†ç±»: {cat_str} | VLMè°ƒç”¨: {vlm_calls}æ¬¡")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)[:100]}")
            
            # é˜¶æ®µ5: ç”Ÿæˆç»“æ„åŒ–å¤§çº²ï¼ˆå«å›¾ç‰‡ä¸Šä¸‹æ–‡ï¼‰
            yield make_msg("stage", stage="generating")
            yield make_msg("progress", percent=65)
            yield make_msg("log", level="info", message="ğŸ“‘ [OutlineGenerator] ç”Ÿæˆç»“æ„åŒ–å¤§çº²ï¼ˆå«å›¾ç‰‡ä¸Šä¸‹æ–‡ï¼‰...")
            
            from ..output.outline_generator import OutlineGenerator
            outline_generator = OutlineGenerator(_config.get_llm_client(), model=_config.llm.model)
            
            try:
                structured_outline = await outline_generator.generate(state)
                yield make_msg("log", level="success", message=f"ğŸ“‘ [OutlineGenerator] ç”Ÿæˆäº† {len(structured_outline)} ä¸ªç« èŠ‚")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ5ç»Ÿè®¡] ç« èŠ‚æ•°: {len(structured_outline)} | LLMè°ƒç”¨: 1æ¬¡")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)[:100]}, ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                structured_outline = outline_generator._generate_fallback_outline(state)
            
            # é˜¶æ®µ6: å›¾ç‰‡åˆ†é…ï¼ˆåŸºäºVLMåˆ†æç»“æœï¼‰
            yield make_msg("progress", percent=75)
            yield make_msg("log", level="info", message="ğŸ¯ [ImageAssigner] åˆ†é…å›¾ç‰‡åˆ°ç« èŠ‚...")
            
            from ..output.image_assigner import ImageAssigner
            image_assigner = ImageAssigner()
            
            assign_logs = []
            def capture_assign_log(msg):
                assign_logs.append(msg)
            
            try:
                structured_outline = await image_assigner.assign(state, structured_outline, on_log=capture_assign_log)
                
                # è¾“å‡ºåˆ†é…ä¸ç”Ÿæˆæ—¥å¿—
                for log in assign_logs:
                    yield make_msg("log", level="info", message=f"  {log}")
                
                assigned_count = sum(len(section.get('images', [])) for section in structured_outline)
                yield make_msg("log", level="success", message=f"ğŸ¯ [ImageAssigner] åˆ†é…äº† {assigned_count} å¼ å›¾ç‰‡")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ6ç»Ÿè®¡] åˆ†é…å›¾ç‰‡: {assigned_count}å¼ ")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å›¾ç‰‡åˆ†é…å¤±è´¥: {str(e)[:100]}")
            
            # é˜¶æ®µ7: ç”ŸæˆHTMLæŠ¥å‘Š
            yield make_msg("progress", percent=85)
            yield make_msg("log", level="info", message="ğŸ“ [Writer] ç”Ÿæˆå›¾æ–‡äº¤é”™æŠ¥å‘Š...")
            html_generator = HTMLReportGenerator(_config.get_llm_client(), model=_config.llm.model)
            
            try:
                html_report = await html_generator.generate(state)
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  LLMç”Ÿæˆå¤±è´¥: {str(e)[:100]}, ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿")
                html_report = html_generator.generate_fallback_html(state)
            
            yield make_msg("progress", percent=100)
            yield make_msg("log", level="success", message="âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ7ç»Ÿè®¡] æŠ¥å‘ŠHTMLé•¿åº¦: {len(html_report)}å­—ç¬¦ | ç« èŠ‚æ•°: {len(structured_outline)} | LLMè°ƒç”¨: {len(structured_outline)+1}æ¬¡")
            
            # ä¼ é€’æŠ¥å‘Šæ•°æ®ç»™å‰ç«¯ï¼ˆåŒ…å«ç»“æ„åŒ–å¤§çº²ï¼‰
            report_data = {
                "topic": research_topic,
                "insights": state.insights,
                "outline": structured_outline,  # æ–°å¢ï¼šç»“æ„åŒ–å¤§çº²
                "notes": [
                    {
                        "id": note.preview.id,
                        "title": note.detail.title or note.preview.title,
                        "content": note.detail.content or note.preview.content_preview,  # å…¨é‡å†…å®¹
                        "author": note.detail.author or note.preview.author,
                        "likes": note.detail.likes or note.preview.likes,
                        "images": note.detail.images if note.detail.images else [],  # å…¨é‡å›¾ç‰‡
                        "url": note.detail.url or note.preview.url
                    }
                    for note in state.documents  # å…¨é‡ç¬”è®°
                ]
            }
            yield make_msg("report", **report_data)
            
            final_status = "completed"
            
            # ä¿å­˜å®Œæ•´æŠ¥å‘Šæ•°æ®åˆ°å†å²è®°å½•ï¼ˆç”¨äºå†å²æ¢å¤ç¼–è¾‘ï¼‰
            history_service.save_report_data(
                record_id=record_id,
                outline=structured_outline,
                notes=report_data["notes"],
                insights=state.insights or {}
            )
            history_service.update(record_id, {"status": "completed"})
            
            yield make_msg("complete")
            
        except Exception as e:
            yield make_msg("log", level="error", message=f"âŒ ç ”ç©¶å¤±è´¥: {str(e)}")
            history_service.update(record_id, {"status": "failed"})
            yield make_msg("complete")
        
        finally:
            # æ–­å¼€MCPè¿æ¥
            if _mcp_client:
                try:
                    await _mcp_client.disconnect()
                except:
                    pass
    
    return EventSourceResponse(event_generator())


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "mcp_configured": _mcp_client is not None,
        "timestamp": datetime.now().isoformat()
    }


# ========== è®¾ç½® API ==========

class LLMTestRequest(BaseModel):
    """LLM æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.get("/api/settings")
async def get_settings():
    """è·å–è®¾ç½®ï¼ˆè„±æ•ï¼‰"""
    service = get_settings_service()
    return service.get_masked()


@app.post("/api/settings")
async def save_settings(settings: Settings):
    """ä¿å­˜è®¾ç½®"""
    service = get_settings_service()
    service.save(settings)
    return {"status": "ok", "message": "è®¾ç½®å·²ä¿å­˜"}


@app.post("/api/settings/test")
async def test_llm_connection(request: LLMTestRequest):
    """æµ‹è¯• LLM è¿æ¥"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=request.apiKey,
            base_url=request.baseUrl
        )
        
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        response = await client.chat.completions.create(
            model=request.model,
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=5
        )
        
        return {"status": "ok", "message": "è¿æ¥æˆåŠŸ"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"è¿æ¥å¤±è´¥: {str(e)}")


class VLMTestRequest(BaseModel):
    """VLM æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test-vlm")
async def test_vlm_connection(request: VLMTestRequest):
    """æµ‹è¯• VLM è¿æ¥ï¼ˆå‘é€å›¾ç‰‡éªŒè¯è¯·æ±‚ï¼‰"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=request.apiKey,
            base_url=request.baseUrl,
            timeout=30.0  # æ·»åŠ è¶…æ—¶è®¾ç½®
        )
        
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ base64 ç¼–ç çš„æµ‹è¯•å›¾ç‰‡ï¼ˆ100x100 çº¢è‰²æ–¹å—ï¼‰
        # æ»¡è¶³æ¨¡å‹å¯¹å›¾ç‰‡å°ºå¯¸çš„æœ€ä½è¦æ±‚(å®½é«˜>10)
        test_image_base64 = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAAaklEQVR42u3QMQEAAAwCIPuX1hjL8AETDlNVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVXVH2YBy8IABVQAAABJRU5ErkJggg=="
        
        response = await client.chat.completions.create(
            model=request.model,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": "What color is this image? Answer in one word."},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": test_image_base64
                        }
                    }
                ]
            }],
            max_tokens=10
        )
        
        return {"status": "ok", "message": f"VLM è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"VLM è¿æ¥å¤±è´¥: {str(e)}")


class ImageGenTestRequest(BaseModel):
    """å›¾ç‰‡ç”Ÿæˆæ¨¡å‹æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test-imagegen")
async def test_imagegen_connection(request: ImageGenTestRequest):
    """æµ‹è¯•å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥"""
    import httpx
    
    try:
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„æµ‹è¯•æ–¹å¼
        if "wanx" in request.model.lower():
            # é€šä¹‰ä¸‡ç›¸ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{request.baseUrl}/services/aigc/text2image/image-synthesis",
                    headers={
                        "Authorization": f"Bearer {request.apiKey}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": request.model,
                        "input": {"prompt": "test"},
                        "parameters": {"n": 1, "size": "256*256"}
                    }
                )
                if response.status_code in [200, 202]:  # 202 è¡¨ç¤ºå¼‚æ­¥ä»»åŠ¡å·²æ¥å—
                    return {"status": "ok", "message": f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text[:200]}")
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
            from openai import AsyncOpenAI
            client = AsyncOpenAI(
                api_key=request.apiKey,
                base_url=request.baseUrl
            )
            # åªæµ‹è¯•è¿æ¥ï¼Œä¸å®é™…ç”Ÿæˆå›¾ç‰‡ï¼ˆé¿å…æ¶ˆè€—é…é¢ï¼‰
            # é€šè¿‡ models.list æ¥éªŒè¯ API æ˜¯å¦å¯ç”¨
            await client.models.list()
            return {"status": "ok", "message": f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹ API è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
            
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")


@app.post("/api/settings/test-mcp")
async def test_mcp_connection():
    """æµ‹è¯• MCP è¿æ¥ï¼ˆæ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€ï¼‰"""
    global _mcp_client
    
    if not _mcp_client:
        raise HTTPException(
            status_code=400, 
            detail="MCP å®¢æˆ·ç«¯æœªé…ç½®ã€‚è¯·ç¡®ä¿ REDNOTE_MCP_PATH ç¯å¢ƒå˜é‡å·²è®¾ç½®ã€‚"
        )
    
    try:
        # è¿æ¥ MCP
        await _mcp_client.connect()
        
        # å°è¯•æœç´¢ä¸€ä¸ªæµ‹è¯•å…³é”®è¯
        results = await _mcp_client.search_notes("æµ‹è¯•", limit=1)
        
        # æ–­å¼€è¿æ¥
        await _mcp_client.disconnect()
        
        if results:
            return {
                "status": "ok", 
                "message": f"MCP è¿æ¥æˆåŠŸï¼å°çº¢ä¹¦ç™»å½•çŠ¶æ€æ­£å¸¸ï¼Œæ‰¾åˆ° {len(results)} æ¡æµ‹è¯•ç»“æœã€‚"
            }
        else:
            return {
                "status": "ok", 
                "message": "MCP è¿æ¥æˆåŠŸï¼ä½†æœªæ‰¾åˆ°æµ‹è¯•ç»“æœï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•å°çº¢ä¹¦ã€‚"
            }
            
    except Exception as e:
        error_msg = str(e)
        if "login" in error_msg.lower() or "ç™»å½•" in error_msg:
            raise HTTPException(
                status_code=400, 
                detail=f"MCP è¿æ¥å¤±è´¥ï¼šéœ€è¦é‡æ–°ç™»å½•å°çº¢ä¹¦ã€‚é”™è¯¯: {error_msg[:100]}"
            )
        raise HTTPException(status_code=400, detail=f"MCP è¿æ¥å¤±è´¥: {error_msg[:200]}")




from ..services.history import get_history_service, ResearchRecord


@app.get("/api/history")
async def list_history(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=50),
    status: Optional[str] = None
):
    """è·å–å†å²è®°å½•åˆ—è¡¨"""
    service = get_history_service()
    return service.list(page=page, page_size=page_size, status=status)


@app.get("/api/history/{record_id}")
async def get_history_record(record_id: str):
    """è·å–å•ä¸ªå†å²è®°å½•ï¼ˆå…ƒæ•°æ®ï¼‰"""
    service = get_history_service()
    record = service.get(record_id)
    if not record:
        raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
    return record.model_dump()


@app.get("/api/history/{record_id}/full")
async def get_history_record_full(record_id: str):
    """è·å–å®Œæ•´å†å²è®°å½•ï¼ˆåŒ…å«æŠ¥å‘Šæ•°æ®ï¼Œç”¨äºå†å²æ¢å¤ç¼–è¾‘ï¼‰"""
    service = get_history_service()
    record = service.get_full(record_id)
    if not record:
        raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
    return record.model_dump()


@app.delete("/api/history/{record_id}")
async def delete_history_record(record_id: str):
    """åˆ é™¤å†å²è®°å½•"""
    service = get_history_service()
    if service.delete(record_id):
        return {"status": "ok", "message": "å·²åˆ é™¤"}
    raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")


@app.get("/api/history/search")
async def search_history(
    keyword: str = Query(..., min_length=1),
    limit: int = Query(10, ge=1, le=50)
):
    """æœç´¢å†å²è®°å½•"""
    service = get_history_service()
    results = service.search(keyword, limit)
    return [r.model_dump() for r in results]


# ========== å›¾ç‰‡éªŒè¯ API ==========

class ImageValidateRequest(BaseModel):
    """å›¾ç‰‡éªŒè¯è¯·æ±‚"""
    image_url: str
    context: str
    topic: str = ""


@app.post("/api/validate-image")
async def validate_image(request: ImageValidateRequest):
    """éªŒè¯å›¾ç‰‡ä¸å†…å®¹çš„ç›¸å…³æ€§"""
    from ..agents.image_validator import ImageValidator
    
    validator = ImageValidator()
    try:
        result = await validator.validate(
            image_source=request.image_url,
            context=request.context,
            topic=request.topic
        )
        return result.model_dump()
    finally:
        await validator.close()


class BatchImageValidateRequest(BaseModel):
    """æ‰¹é‡å›¾ç‰‡éªŒè¯è¯·æ±‚"""
    images: list[dict]  # [{url: str, caption?: str}, ...]
    context: str
    topic: str = ""


@app.post("/api/validate-images")
async def validate_images_batch(request: BatchImageValidateRequest):
    """æ‰¹é‡éªŒè¯å›¾ç‰‡"""
    from ..agents.image_validator import validate_images_batch
    
    results = await validate_images_batch(
        images=request.images,
        context=request.context,
        topic=request.topic
    )
    return results


# ========== æŠ¥å‘Šå¯¼å‡º API ==========

class ExportRequest(BaseModel):
    """å¯¼å‡ºè¯·æ±‚"""
    format: str  # 'markdown' | 'pdf'
    topic: str
    insights: dict = {}
    outline: list = []
    notes: list = []


@app.post("/api/export")
async def export_report(request: ExportRequest):
    """å¯¼å‡ºæŠ¥å‘Šä¸ºä¸åŒæ ¼å¼"""
    from fastapi.responses import Response
    from ..output.exporter import ReportExporter
    
    if request.format == "markdown":
        content = ReportExporter.to_markdown(
            topic=request.topic,
            insights=request.insights,
            outline=request.outline,
            notes=request.notes
        )
        return Response(
            content=content,
            media_type="text/markdown",
            headers={
                "Content-Disposition": f'attachment; filename="report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md"'
            }
        )
    
    elif request.format == "pdf":
        # PDFéœ€è¦å…ˆç”ŸæˆHTMLå†è½¬æ¢
        html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>{request.topic}</title>
<style>body{{font-family:sans-serif;max-width:800px;margin:0 auto;padding:20px;}}
h1{{color:#ff2442;}}h2{{border-bottom:2px solid #ff2442;padding-bottom:8px;}}</style>
</head><body>
<h1>{request.topic}</h1>
{"".join([f'<section><h2>{s.get("title","")}</h2><p>{s.get("content","")}</p></section>' for s in request.outline])}
</body></html>"""
        
        try:
            pdf_bytes = await ReportExporter.to_pdf(html)
            if pdf_bytes:
                return Response(
                    content=pdf_bytes,
                    media_type="application/pdf",
                    headers={
                        "Content-Disposition": f'attachment; filename="report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pdf"'
                    }
                )
            else:
                raise HTTPException(status_code=500, detail="PDFè½¬æ¢è¿”å›ç©ºç»“æœ")
        except ImportError as e:
            raise HTTPException(status_code=500, detail=str(e))
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"PDFå¯¼å‡ºå¤±è´¥: {str(e)}")
    
    else:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ ¼å¼: {request.format}")


# ============ è®¾ç½®ç›¸å…³ API ============

def get_effective_config() -> Config:
    """
    è·å–æœ‰æ•ˆé…ç½®ï¼ˆUI è®¾ç½®ä¼˜å…ˆï¼Œç„¶å ENVï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1. UI è®¾ç½®ï¼ˆå¦‚æœé…ç½®äº† API Keyï¼‰
    2. ç¯å¢ƒå˜é‡é…ç½®
    """
    config = Config.from_env()
    ui_settings = get_settings_service().load()
    
    # UI è®¾ç½®è¦†ç›– ENVï¼ˆå¦‚æœ UI è®¾ç½®äº† API Keyï¼‰
    if ui_settings.llm.api_key:
        config.llm.api_key = ui_settings.llm.api_key
        config.llm.base_url = ui_settings.llm.base_url
        config.llm.model = ui_settings.llm.model
    
    return config


@app.get("/api/settings")
async def get_settings():
    """è·å–è„±æ•åçš„è®¾ç½®"""
    return get_settings_service().get_masked()


class SettingsUpdateRequest(BaseModel):
    """è®¾ç½®æ›´æ–°è¯·æ±‚"""
    llm: dict = {}
    vlm: dict = {}
    imageGen: dict = {}


@app.post("/api/settings")
async def save_settings(data: SettingsUpdateRequest):
    """ä¿å­˜è®¾ç½®"""
    from ..services.settings import LLMSettings, VLMSettings, ImageGenSettings
    
    # è½¬æ¢å­—æ®µåï¼ˆå‰ç«¯ä½¿ç”¨ camelCaseï¼Œåç«¯ä½¿ç”¨ snake_caseï¼‰
    llm_data = {
        "api_key": data.llm.get("apiKey", ""),
        "base_url": data.llm.get("baseUrl", "https://api-inference.modelscope.cn/v1"),
        "model": data.llm.get("model", "")
    }
    vlm_data = {
        "enabled": data.vlm.get("enabled", False),
        "api_key": data.vlm.get("apiKey", ""),
        "base_url": data.vlm.get("baseUrl", ""),
        "model": data.vlm.get("model", ""),
        "rate_limit_mode": data.vlm.get("rateLimitMode", True)
    }
    image_gen_data = {
        "enabled": data.imageGen.get("enabled", False),
        "api_key": data.imageGen.get("apiKey", ""),
        "base_url": data.imageGen.get("baseUrl", ""),
        "model": data.imageGen.get("model", ""),
        "rate_limit_mode": data.imageGen.get("rateLimitMode", True)
    }
    
    settings = Settings(
        llm=LLMSettings(**llm_data),
        vlm=VLMSettings(**vlm_data),
        imageGen=ImageGenSettings(**image_gen_data)
    )
    get_settings_service().save(settings)
    return {"success": True, "message": "è®¾ç½®å·²ä¿å­˜"}


class LLMTestRequest(BaseModel):
    """LLM è¿æ¥æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test")
async def test_llm_connection(data: LLMTestRequest):
    """æµ‹è¯• LLM è¿æ¥"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=data.apiKey,
            base_url=data.baseUrl
        )
        response = await client.chat.completions.create(
            model=data.model,
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=5
        )
        return {
            "success": True, 
            "message": f"è¿æ¥æˆåŠŸï¼æ¨¡å‹: {response.model}"
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


# ========== SPA è·¯ç”±ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ API è·¯ç”±ä¹‹åæ³¨å†Œï¼‰==========

_static_dir = Path(__file__).parent / "static"
if _static_dir.exists() and (_static_dir / "index.html").exists():
    @app.get("/{full_path:path}", include_in_schema=False)
    async def serve_spa(full_path: str):
        """SPA å…œåº•è·¯ç”±ï¼šè¿”å› index.html æˆ–é™æ€æ–‡ä»¶"""
        # API è·¯ç”±ä¸å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µä¸‹ä¸ä¼šåˆ°è¿™é‡Œï¼Œå› ä¸º API è·¯ç”±å·²å…ˆæ³¨å†Œï¼‰
        if full_path.startswith("api/"):
            raise HTTPException(status_code=404, detail="API not found")
        
        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚é™æ€æ–‡ä»¶
        requested_file = _static_dir / full_path
        if requested_file.exists() and requested_file.is_file():
            return FileResponse(str(requested_file))
        
        # å…¶ä»–æ‰€æœ‰è¯·æ±‚è¿”å› index.htmlï¼ˆSPA è·¯ç”±ï¼‰
        return FileResponse(str(_static_dir / "index.html"))


# ç›´æ¥è¿è¡Œå…¥å£
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
