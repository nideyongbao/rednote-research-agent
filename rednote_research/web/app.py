"""FastAPI Webåº”ç”¨ - æä¾›SSEå®æ—¶ç ”ç©¶ç•Œé¢"""

import os
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from sse_starlette.sse import EventSourceResponse
from pydantic import BaseModel

from ..config import Config
from ..state import ResearchState
from ..mcp import XiaohongshuHTTPClient
from ..agents.orchestrator import ResearchOrchestrator
from ..output.html_generator import HTMLReportGenerator
from ..services.settings import get_settings_service, Settings


# å…¨å±€çŠ¶æ€
_orchestrator: Optional[ResearchOrchestrator] = None
_mcp_client: Optional[XiaohongshuHTTPClient] = None
_config: Optional[Config] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global _orchestrator, _mcp_client, _config
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    _config = Config.from_env()
    
    # MCPå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ HTTP APIï¼‰
    mcp_url = os.getenv("XIAOHONGSHU_MCP_URL", "http://localhost:18060")
    _mcp_client = XiaohongshuHTTPClient(base_url=mcp_url)
    await _mcp_client.connect()
    _orchestrator = ResearchOrchestrator(_config, _mcp_client)
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    if _mcp_client:
        await _mcp_client.disconnect()


def create_app() -> FastAPI:
    """åˆ›å»ºFastAPIåº”ç”¨"""
    app = FastAPI(
        title="RedNote Research Agent",
        description="åŸºäºMCPçš„å°çº¢ä¹¦æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“",
        version="0.1.0",
        lifespan=lifespan
    )
    
    # æŒ‚è½½é™æ€æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼šå‰ç«¯æ„å»ºäº§ç‰©ï¼‰
    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        assets_dir = static_dir / "assets"
        if assets_dir.exists():
            app.mount("/assets", StaticFiles(directory=str(assets_dir)), name="assets")
    
    # æ³¨æ„ï¼šSPA catch-all è·¯ç”±åœ¨æ–‡ä»¶æœ«å°¾æ³¨å†Œï¼Œç¡®ä¿ API è·¯ç”±ä¼˜å…ˆåŒ¹é…
    return app


app = create_app()



@app.get("/api/research")
async def research_stream(topic: str = Query(None), task: str = Query(None, min_length=2)):
    """
    SSEæµå¼è¿”å›ç ”ç©¶è¿›åº¦å’Œç»“æœ
    
    äº‹ä»¶ç±»å‹:
    - message: JSONæ ¼å¼çš„æ¶ˆæ¯ï¼ŒåŒ…å« type, level, message, stage, stats ç­‰å­—æ®µ
    
    æ¶ˆæ¯ç±»å‹(type):
    - log: è¿›åº¦æ—¥å¿—
    - stage: é˜¶æ®µåˆ‡æ¢
    - stats: ç»Ÿè®¡æ›´æ–°
    - complete: å®Œæˆä¿¡å·
    - error: é”™è¯¯ä¿¡æ¯
    """
    import json
    global _orchestrator, _mcp_client, _config
    
    # å…¼å®¹æ–°æ—§å‚æ•°å
    research_topic = topic or task
    if not research_topic or len(research_topic) < 2:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æœ‰æ•ˆçš„ç ”ç©¶ä¸»é¢˜")
    
    # åˆ›å»ºå†å²è®°å½•
    from ..services.history import get_history_service
    history_service = get_history_service()
    record = history_service.create(research_topic)
    record_id = record.id
    
    async def event_generator():
        stats = {"notesFound": 0, "contentsAnalyzed": 0, "insightsExtracted": 0}
        final_status = "failed"  # é»˜è®¤å¤±è´¥ï¼ŒæˆåŠŸæ—¶æ›´æ–°
        
        def make_msg(msg_type: str, **kwargs) -> dict:
            """ç”Ÿæˆæ ‡å‡†æ¶ˆæ¯æ ¼å¼"""
            return {"data": json.dumps({"type": msg_type, "recordId": record_id, **kwargs}, ensure_ascii=False)}
        
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            history_service.update(record_id, {"status": "running"})
            
            yield make_msg("log", level="info", message=f"ğŸš€ å¼€å§‹ç ”ç©¶: {research_topic}")
            yield make_msg("stage", stage="planning")
            
            # æ£€æŸ¥MCPå®¢æˆ·ç«¯
            if not _mcp_client:
                yield make_msg("log", level="warning", message="MCPå®¢æˆ·ç«¯æœªé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                # æ¨¡æ‹Ÿç ”ç©¶æµç¨‹
                yield make_msg("log", level="info", message="ğŸ“‹ [Planner] åˆ†æç ”ç©¶ä¸»é¢˜...")
                await asyncio.sleep(1)
                yield make_msg("log", level="success", message="ğŸ“‹ [Planner] ç”Ÿæˆäº† 3 ä¸ªæœç´¢å…³é”®è¯")
                
                yield make_msg("stage", stage="searching")
                yield make_msg("log", level="info", message="ğŸ” [Searcher] å¼€å§‹æœç´¢ç¬”è®°...")
                await asyncio.sleep(1)
                stats["notesFound"] = 15
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ” [Searcher] æ”¶é›†äº† {stats['notesFound']} ç¯‡ç¬”è®°")
                
                yield make_msg("stage", stage="analyzing")
                yield make_msg("log", level="info", message="ğŸ§  [Analyzer] åˆ†ææ•°æ®ä¸­...")
                await asyncio.sleep(1)
                stats["contentsAnalyzed"] = 15
                stats["insightsExtracted"] = 8
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ§  [Analyzer] æå–äº† {stats['insightsExtracted']} æ¡æ ¸å¿ƒå‘ç°")
                
                yield make_msg("stage", stage="generating")
                yield make_msg("log", level="info", message="ğŸ“ [Writer] ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...")
                await asyncio.sleep(1)
                yield make_msg("log", level="success", message="âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                yield make_msg("complete")
                return
            
            # è¿æ¥MCP
            yield make_msg("log", level="info", message="ğŸ“¡ è¿æ¥å°çº¢ä¹¦MCPæœåŠ¡...")
            await _mcp_client.connect()
            yield make_msg("log", level="success", message="âœ… MCPè¿æ¥æˆåŠŸ")
            
            # åˆ›å»ºç¼–æ’å™¨
            orchestrator = ResearchOrchestrator(_config, _mcp_client)
            
            # æ‰§è¡Œç ”ç©¶
            state = ResearchState(task=research_topic)
            
            # é˜¶æ®µ1: è§„åˆ’
            yield make_msg("progress", percent=10)
            yield make_msg("log", level="info", message="ğŸ“‹ [Planner] åˆ†æç ”ç©¶ä¸»é¢˜...")
            state = await orchestrator.planner.run(state)
            if state.plan:
                yield make_msg("log", level="success", message=f"ğŸ“‹ [Planner] ç”Ÿæˆäº† {len(state.plan.keywords)} ä¸ªæœç´¢å…³é”®è¯")
                yield make_msg("log", level="info", message=f"ğŸ’¡ ç†è§£: {state.plan.understanding}")
                yield make_msg("log", level="info", message=f"ğŸ“Š ç»´åº¦: {', '.join(state.plan.dimensions)}")
                for kw in state.plan.keywords:
                    yield make_msg("log", level="info", message=f"  - {kw}")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ1ç»Ÿè®¡] å…³é”®è¯: {len(state.plan.keywords)}ä¸ª | ç»´åº¦: {len(state.plan.dimensions)}ä¸ª | LLMè°ƒç”¨: 1æ¬¡")
            
            # é˜¶æ®µ2: æœç´¢
            yield make_msg("stage", stage="searching")
            yield make_msg("progress", percent=25)
            yield make_msg("log", level="info", message="ğŸ” [Searcher] å¼€å§‹æœç´¢ç¬”è®°...")
            
            # æ”¶é›†æœç´¢æ—¥å¿—ç”¨äºå‰ç«¯æ˜¾ç¤º
            search_logs = []
            def capture_log(msg):
                search_logs.append(msg)
            
            state = await orchestrator.searcher.run(state, on_log=capture_log)
            
            # è¾“å‡ºæ¯ä¸ªå…³é”®è¯çš„æœç´¢ç»“æœåˆ°å‰ç«¯
            for log in search_logs:
                yield make_msg("log", level="info", message=f"  {log}")
            
            stats["notesFound"] = len(state.documents)
            yield make_msg("stats", stats=stats)
            yield make_msg("log", level="success", message=f"ğŸ” [Searcher] æ”¶é›†äº† {stats['notesFound']} ç¯‡ç¬”è®°")
            
            # è®¡ç®—å¹¶è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
            total_images = sum(len(note.detail.images) for note in state.documents if note.detail.images)
            total_text_length = sum(len(note.detail.content or "") for note in state.documents)
            avg_text_length = total_text_length // len(state.documents) if state.documents else 0
            yield make_msg("log", level="info", message=f"ğŸ“Š [ç»Ÿè®¡] å…± {total_images} å¼ å›¾ç‰‡ï¼Œæ€»æ–‡æœ¬ {total_text_length} å­—ï¼Œå¹³å‡æ¯ç¯‡ {avg_text_length} å­—")
            
            # é˜¶æ®µ3: åˆ†æ
            yield make_msg("stage", stage="analyzing")
            yield make_msg("progress", percent=45)
            yield make_msg("log", level="info", message="ğŸ§  [Analyzer] åˆ†ææ•°æ®ä¸­...")
            state = await orchestrator.analyzer.run(state)
            stats["contentsAnalyzed"] = len(state.documents)
            if state.insights:
                findings = state.insights.get("key_findings", [])
                stats["insightsExtracted"] = len(findings)
                yield make_msg("stats", stats=stats)
                yield make_msg("log", level="success", message=f"ğŸ§  [Analyzer] æå–äº† {stats['insightsExtracted']} æ¡æ ¸å¿ƒå‘ç°")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ3ç»Ÿè®¡] åˆ†æç¬”è®°: {len(state.documents)}ç¯‡ | æå–å‘ç°: {stats['insightsExtracted']}æ¡ | LLMè°ƒç”¨: 1æ¬¡")
            
            # é˜¶æ®µ4: å›¾ç‰‡VLMåˆ†æï¼ˆæå‰åˆ°å¤§çº²ä¹‹å‰ï¼‰
            yield make_msg("progress", percent=55)
            yield make_msg("log", level="info", message="ğŸ–¼ï¸ [ImageAnalyzer] VLMåˆ†æå›¾ç‰‡...")
            
            from ..output.image_analyzer import ImageAnalyzer
            image_analyzer = ImageAnalyzer()
            
            image_logs = []
            def capture_image_log(msg):
                image_logs.append(msg)
            
            try:
                state, img_stats = await image_analyzer.analyze(state, on_log=capture_image_log)
                
                # è¾“å‡ºè¯¦ç»†æ—¥å¿—
                for log in image_logs:
                    yield make_msg("log", level="info", message=f"  {log}")
                
                analyzed_count = len(state.image_analyses)
                usable_count = sum(1 for r in state.image_analyses.values() if r.should_use)
                vlm_calls = img_stats.get("vlm_calls", 0)
                yield make_msg("log", level="success", message=f"ğŸ–¼ï¸ [ImageAnalyzer] åˆ†æäº† {analyzed_count} å¼ å›¾ç‰‡ï¼Œ{usable_count} å¼ å¯ç”¨")
                
                # ç»Ÿè®¡åˆ†ç±»
                categories = {}
                for r in state.image_analyses.values():
                    cat = r.category or "æœªåˆ†ç±»"
                    categories[cat] = categories.get(cat, 0) + 1
                cat_str = ", ".join(f"{k}:{v}" for k, v in categories.items())
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ4ç»Ÿè®¡] åˆ†ç±»: {cat_str} | VLMè°ƒç”¨: {vlm_calls}æ¬¡")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)[:100]}")
            
            # é˜¶æ®µ5: ç”Ÿæˆç»“æ„åŒ–å¤§çº²ï¼ˆå«å›¾ç‰‡ä¸Šä¸‹æ–‡ï¼‰
            yield make_msg("stage", stage="generating")
            yield make_msg("progress", percent=65)
            yield make_msg("log", level="info", message="ğŸ“‘ [OutlineGenerator] ç”Ÿæˆç»“æ„åŒ–å¤§çº²ï¼ˆå«å›¾ç‰‡ä¸Šä¸‹æ–‡ï¼‰...")
            
            from ..output.outline_generator import OutlineGenerator
            outline_generator = OutlineGenerator(_config.get_llm_client(), model=_config.llm.model)
            
            try:
                structured_outline = await outline_generator.generate(state)
                yield make_msg("log", level="success", message=f"ğŸ“‘ [OutlineGenerator] ç”Ÿæˆäº† {len(structured_outline)} ä¸ªç« èŠ‚")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ5ç»Ÿè®¡] ç« èŠ‚æ•°: {len(structured_outline)} | LLMè°ƒç”¨: 1æ¬¡")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)[:100]}, ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                structured_outline = outline_generator._generate_fallback_outline(state)
            
            # é˜¶æ®µ6: å›¾ç‰‡åˆ†é…ï¼ˆåŸºäºVLMåˆ†æç»“æœï¼‰
            yield make_msg("progress", percent=75)
            yield make_msg("log", level="info", message="ğŸ¯ [ImageAssigner] åˆ†é…å›¾ç‰‡åˆ°ç« èŠ‚...")
            
            from ..output.image_assigner import ImageAssigner
            image_assigner = ImageAssigner()
            
            assign_logs = []
            def capture_assign_log(msg):
                assign_logs.append(msg)
            
            try:
                structured_outline = await image_assigner.assign(state, structured_outline, on_log=capture_assign_log)
                
                # è¾“å‡ºåˆ†é…ä¸ç”Ÿæˆæ—¥å¿—
                for log in assign_logs:
                    yield make_msg("log", level="info", message=f"  {log}")
                
                assigned_count = sum(len(section.get('images', [])) for section in structured_outline)
                yield make_msg("log", level="success", message=f"ğŸ¯ [ImageAssigner] åˆ†é…äº† {assigned_count} å¼ å›¾ç‰‡")
                yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ6ç»Ÿè®¡] åˆ†é…å›¾ç‰‡: {assigned_count}å¼ ")
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  å›¾ç‰‡åˆ†é…å¤±è´¥: {str(e)[:100]}")
            
            # é˜¶æ®µ7: ç”ŸæˆHTMLæŠ¥å‘Š
            yield make_msg("progress", percent=85)
            yield make_msg("log", level="info", message="ğŸ“ [Writer] ç”Ÿæˆå›¾æ–‡äº¤é”™æŠ¥å‘Š...")
            html_generator = HTMLReportGenerator(_config.get_llm_client(), model=_config.llm.model)
            
            try:
                html_report = await html_generator.generate(state)
            except Exception as e:
                yield make_msg("log", level="warning", message=f"âš  LLMç”Ÿæˆå¤±è´¥: {str(e)[:100]}, ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿")
                html_report = html_generator.generate_fallback_html(state)
            
            yield make_msg("progress", percent=100)
            yield make_msg("log", level="success", message="âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            yield make_msg("log", level="info", message=f"ğŸ“ [é˜¶æ®µ7ç»Ÿè®¡] æŠ¥å‘ŠHTMLé•¿åº¦: {len(html_report)}å­—ç¬¦ | ç« èŠ‚æ•°: {len(structured_outline)} | LLMè°ƒç”¨: {len(structured_outline)+1}æ¬¡")
            
            # ä¼ é€’æŠ¥å‘Šæ•°æ®ç»™å‰ç«¯ï¼ˆåŒ…å«ç»“æ„åŒ–å¤§çº²ï¼‰
            report_data = {
                "topic": research_topic,
                "insights": state.insights,
                "outline": structured_outline,  # æ–°å¢ï¼šç»“æ„åŒ–å¤§çº²
                "notes": [
                    {
                        "id": note.preview.id,
                        "title": note.detail.title or note.preview.title,
                        "content": note.detail.content or note.preview.content_preview,  # å…¨é‡å†…å®¹
                        "author": note.detail.author or note.preview.author,
                        "likes": note.detail.likes or note.preview.likes,
                        "images": note.detail.images if note.detail.images else [],  # å…¨é‡å›¾ç‰‡
                        "url": note.detail.url or note.preview.url
                    }
                    for note in state.documents  # å…¨é‡ç¬”è®°
                ]
            }
            yield make_msg("report", **report_data)
            
            final_status = "completed"
            
            # ä¿å­˜å®Œæ•´æŠ¥å‘Šæ•°æ®åˆ°å†å²è®°å½•ï¼ˆç”¨äºå†å²æ¢å¤ç¼–è¾‘ï¼‰
            history_service.save_report_data(
                record_id=record_id,
                outline=structured_outline,
                notes=report_data["notes"],
                insights=state.insights or {}
            )
            history_service.update(record_id, {"status": "completed"})
            
            yield make_msg("complete")
            
        except Exception as e:
            yield make_msg("log", level="error", message=f"âŒ ç ”ç©¶å¤±è´¥: {str(e)}")
            history_service.update(record_id, {"status": "failed"})
            yield make_msg("complete")
        
        finally:
            # æ–­å¼€MCPè¿æ¥
            if _mcp_client:
                try:
                    await _mcp_client.disconnect()
                except:
                    pass
    
    return EventSourceResponse(event_generator())


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "mcp_configured": _mcp_client is not None,
        "timestamp": datetime.now().isoformat()
    }


# ========== è®¾ç½® API ==========

class LLMTestRequest(BaseModel):
    """LLM æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.get("/api/settings")
async def get_settings():
    """è·å–è®¾ç½®ï¼ˆè„±æ•ï¼‰"""
    service = get_settings_service()
    return service.get_masked()


@app.post("/api/settings")
async def save_settings(settings: Settings):
    """ä¿å­˜è®¾ç½®"""
    service = get_settings_service()
    service.save(settings)
    return {"status": "ok", "message": "è®¾ç½®å·²ä¿å­˜"}


@app.post("/api/settings/test")
async def test_llm_connection(request: LLMTestRequest):
    """æµ‹è¯• LLM è¿æ¥"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=request.apiKey,
            base_url=request.baseUrl
        )
        
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        response = await client.chat.completions.create(
            model=request.model,
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=5
        )
        
        return {"status": "ok", "message": "è¿æ¥æˆåŠŸ"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"è¿æ¥å¤±è´¥: {str(e)}")


class VLMTestRequest(BaseModel):
    """VLM æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test-vlm")
async def test_vlm_connection(request: VLMTestRequest):
    """æµ‹è¯• VLM è¿æ¥ï¼ˆå‘é€å›¾ç‰‡éªŒè¯è¯·æ±‚ï¼‰"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=request.apiKey,
            base_url=request.baseUrl,
            timeout=30.0  # æ·»åŠ è¶…æ—¶è®¾ç½®
        )
        
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ base64 ç¼–ç çš„æµ‹è¯•å›¾ç‰‡ï¼ˆ100x100 çº¢è‰²æ–¹å—ï¼‰
        # æ»¡è¶³æ¨¡å‹å¯¹å›¾ç‰‡å°ºå¯¸çš„æœ€ä½è¦æ±‚(å®½é«˜>10)
        test_image_base64 = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAAaklEQVR42u3QMQEAAAwCIPuX1hjL8AETDlNVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVXVH2YBy8IABVQAAABJRU5ErkJggg=="
        
        response = await client.chat.completions.create(
            model=request.model,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": "What color is this image? Answer in one word."},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": test_image_base64
                        }
                    }
                ]
            }],
            max_tokens=10
        )
        
        return {"status": "ok", "message": f"VLM è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"VLM è¿æ¥å¤±è´¥: {str(e)}")


class ImageGenTestRequest(BaseModel):
    """å›¾ç‰‡ç”Ÿæˆæ¨¡å‹æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test-imagegen")
async def test_imagegen_connection(request: ImageGenTestRequest):
    """æµ‹è¯•å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥"""
    import httpx
    
    try:
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„æµ‹è¯•æ–¹å¼
        if "wanx" in request.model.lower():
            # é€šä¹‰ä¸‡ç›¸ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{request.baseUrl}/services/aigc/text2image/image-synthesis",
                    headers={
                        "Authorization": f"Bearer {request.apiKey}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": request.model,
                        "input": {"prompt": "test"},
                        "parameters": {"n": 1, "size": "256*256"}
                    }
                )
                if response.status_code in [200, 202]:  # 202 è¡¨ç¤ºå¼‚æ­¥ä»»åŠ¡å·²æ¥å—
                    return {"status": "ok", "message": f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text[:200]}")
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
            from openai import AsyncOpenAI
            client = AsyncOpenAI(
                api_key=request.apiKey,
                base_url=request.baseUrl
            )
            # åªæµ‹è¯•è¿æ¥ï¼Œä¸å®é™…ç”Ÿæˆå›¾ç‰‡ï¼ˆé¿å…æ¶ˆè€—é…é¢ï¼‰
            # é€šè¿‡ models.list æ¥éªŒè¯ API æ˜¯å¦å¯ç”¨
            await client.models.list()
            return {"status": "ok", "message": f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹ API è¿æ¥æˆåŠŸï¼æ¨¡å‹: {request.model}"}
            
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"å›¾ç‰‡ç”Ÿæˆæ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")


@app.post("/api/settings/test-mcp")
async def test_mcp_connection():
    """æµ‹è¯• MCP è¿æ¥ï¼ˆå®Œæ•´æµ‹è¯•ï¼šç™»å½•çŠ¶æ€ + æœç´¢ + è·å–è¯¦æƒ…ï¼‰"""
    from ..mcp.http_client import get_mcp_client
    import httpx
    
    try:
        client = get_mcp_client()
        
        # 1. æ£€æŸ¥ç™»å½•çŠ¶æ€
        status = await client.check_login_status()
        
        if not status.get("is_logged_in"):
            return {
                "status": "warning",
                "message": "MCP æœåŠ¡æ­£å¸¸ï¼Œä½†æœªç™»å½•å°çº¢ä¹¦ã€‚è¯·æ‰«ç ç™»å½•ã€‚"
            }
        
        username = status.get('username', 'æœªçŸ¥')
        
        # 2. æµ‹è¯•æœç´¢
        try:
            # ç›´æ¥è°ƒç”¨ API æŸ¥çœ‹åŸå§‹å“åº”
            await client._ensure_connected()
            response = await client._client.post("/api/v1/feeds/search", json={
                "keyword": "å¥¶èŒ¶"
            })
            raw_data = response.json()
            
            if raw_data.get("success"):
                feeds = raw_data.get("data", {}).get("feeds", [])
                search_count = len(feeds)
                
                # 3. æµ‹è¯•è·å–è¯¦æƒ…ï¼ˆå¦‚æœæœ‰æœç´¢ç»“æœï¼‰
                detail_test = ""
                if feeds:
                    first_feed = feeds[0]
                    feed_id = first_feed.get("id", "")
                    xsec_token = first_feed.get("xsecToken", "")
                    title = first_feed.get("noteCard", {}).get("displayTitle", "æ— æ ‡é¢˜")[:20]
                    
                    if feed_id and xsec_token:
                        try:
                            detail_response = await client._client.post("/api/v1/feeds/detail", json={
                                "feed_id": feed_id,
                                "xsec_token": xsec_token
                            })
                            detail_data = detail_response.json()
                            if detail_data.get("success"):
                                note_title = detail_data.get("data", {}).get("title", "")[:15]
                                detail_test = f"ï¼Œè¯¦æƒ…è·å–âœ“({note_title})"
                            else:
                                err_msg = detail_data.get('message', '') or detail_data.get('error', '') or 'æœªçŸ¥é”™è¯¯'
                                detail_test = f"ï¼Œè¯¦æƒ…è·å–âœ—({err_msg[:30]})"
                        except Exception as e:
                            detail_test = f"ï¼Œè¯¦æƒ…è·å–å¼‚å¸¸({str(e)[:30]})"
                    else:
                        detail_test = f"ï¼Œç¼ºå°‘token(id={feed_id[:8] if feed_id else 'N/A'})"
                
                return {
                    "status": "ok",
                    "message": f"MCP è¿æ¥æˆåŠŸï¼ç”¨æˆ·: {username}ï¼Œæœç´¢åˆ° {search_count} æ¡ç»“æœ{detail_test}"
                }
            else:
                return {
                    "status": "warning",
                    "message": f"MCP è¿æ¥æˆåŠŸï¼Œç”¨æˆ·: {username}ï¼Œä½†æœç´¢å¤±è´¥: {raw_data.get('message', 'æœªçŸ¥é”™è¯¯')}"
                }
                
        except Exception as e:
            return {
                "status": "warning",
                "message": f"MCP è¿æ¥æˆåŠŸï¼Œç”¨æˆ·: {username}ï¼Œä½†æœç´¢æµ‹è¯•å¤±è´¥: {str(e)[:100]}"
            }
            
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"MCP è¿æ¥å¤±è´¥: {str(e)[:200]}")


@app.get("/api/mcp/login/status")
async def mcp_login_status():
    """è·å–å°çº¢ä¹¦ç™»å½•çŠ¶æ€"""
    from ..mcp.http_client import get_mcp_client
    
    try:
        client = get_mcp_client()
        status = await client.check_login_status()
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç™»å½•çŠ¶æ€å¤±è´¥: {str(e)}")


@app.get("/api/mcp/login/qrcode")
async def mcp_login_qrcode():
    """è·å–å°çº¢ä¹¦ç™»å½•äºŒç»´ç """
    from ..mcp.http_client import get_mcp_client
    
    try:
        client = get_mcp_client()
        qr_data = await client.get_login_qrcode()
        return {
            "success": True,
            "data": qr_data
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–äºŒç»´ç å¤±è´¥: {str(e)}")




from ..services.history import get_history_service, ResearchRecord


@app.get("/api/history")
async def list_history(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=50),
    status: Optional[str] = None
):
    """è·å–å†å²è®°å½•åˆ—è¡¨"""
    service = get_history_service()
    return service.list(page=page, page_size=page_size, status=status)


@app.get("/api/history/{record_id}")
async def get_history_record(record_id: str):
    """è·å–å•ä¸ªå†å²è®°å½•ï¼ˆå…ƒæ•°æ®ï¼‰"""
    service = get_history_service()
    record = service.get(record_id)
    if not record:
        raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
    return record.model_dump()


@app.get("/api/history/{record_id}/full")
async def get_history_record_full(record_id: str):
    """è·å–å®Œæ•´å†å²è®°å½•ï¼ˆåŒ…å«æŠ¥å‘Šæ•°æ®ï¼Œç”¨äºå†å²æ¢å¤ç¼–è¾‘ï¼‰"""
    service = get_history_service()
    record = service.get_full(record_id)
    if not record:
        raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
    return record.model_dump()


@app.delete("/api/history/{record_id}")
async def delete_history_record(record_id: str):
    """åˆ é™¤å†å²è®°å½•"""
    service = get_history_service()
    if service.delete(record_id):
        return {"status": "ok", "message": "å·²åˆ é™¤"}
    raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")


@app.get("/api/history/search")
async def search_history(
    keyword: str = Query(..., min_length=1),
    limit: int = Query(10, ge=1, le=50)
):
    """æœç´¢å†å²è®°å½•"""
    service = get_history_service()
    results = service.search(keyword, limit)
    return [r.model_dump() for r in results]


# ========== å›¾ç‰‡éªŒè¯ API ==========

class ImageValidateRequest(BaseModel):
    """å›¾ç‰‡éªŒè¯è¯·æ±‚"""
    image_url: str
    context: str
    topic: str = ""


@app.post("/api/validate-image")
async def validate_image(request: ImageValidateRequest):
    """éªŒè¯å›¾ç‰‡ä¸å†…å®¹çš„ç›¸å…³æ€§"""
    from ..agents.image_validator import ImageValidator
    
    validator = ImageValidator()
    try:
        result = await validator.validate(
            image_source=request.image_url,
            context=request.context,
            topic=request.topic
        )
        return result.model_dump()
    finally:
        await validator.close()


class BatchImageValidateRequest(BaseModel):
    """æ‰¹é‡å›¾ç‰‡éªŒè¯è¯·æ±‚"""
    images: list[dict]  # [{url: str, caption?: str}, ...]
    context: str
    topic: str = ""


@app.post("/api/validate-images")
async def validate_images_batch(request: BatchImageValidateRequest):
    """æ‰¹é‡éªŒè¯å›¾ç‰‡"""
    from ..agents.image_validator import validate_images_batch
    
    results = await validate_images_batch(
        images=request.images,
        context=request.context,
        topic=request.topic
    )
    return results


# ========== æŠ¥å‘Šå¯¼å‡º API ==========

class ExportRequest(BaseModel):
    """å¯¼å‡ºè¯·æ±‚"""
    format: str  # 'markdown' | 'pdf'
    topic: str
    insights: dict = {}
    outline: list = []
    notes: list = []


@app.post("/api/export")
async def export_report(request: ExportRequest):
    """å¯¼å‡ºæŠ¥å‘Šä¸ºä¸åŒæ ¼å¼"""
    from fastapi.responses import Response
    from ..output.exporter import ReportExporter
    
    if request.format == "markdown":
        content = ReportExporter.to_markdown(
            topic=request.topic,
            insights=request.insights,
            outline=request.outline,
            notes=request.notes
        )
        return Response(
            content=content,
            media_type="text/markdown",
            headers={
                "Content-Disposition": f'attachment; filename="report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md"'
            }
        )
    
    elif request.format == "pdf":
        # PDFéœ€è¦å…ˆç”ŸæˆHTMLå†è½¬æ¢
        html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>{request.topic}</title>
<style>body{{font-family:sans-serif;max-width:800px;margin:0 auto;padding:20px;}}
h1{{color:#ff2442;}}h2{{border-bottom:2px solid #ff2442;padding-bottom:8px;}}</style>
</head><body>
<h1>{request.topic}</h1>
{"".join([f'<section><h2>{s.get("title","")}</h2><p>{s.get("content","")}</p></section>' for s in request.outline])}
</body></html>"""
        
        try:
            pdf_bytes = await ReportExporter.to_pdf(html)
            if pdf_bytes:
                return Response(
                    content=pdf_bytes,
                    media_type="application/pdf",
                    headers={
                        "Content-Disposition": f'attachment; filename="report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pdf"'
                    }
                )
            else:
                raise HTTPException(status_code=500, detail="PDFè½¬æ¢è¿”å›ç©ºç»“æœ")
        except ImportError as e:
            raise HTTPException(status_code=500, detail=str(e))
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"PDFå¯¼å‡ºå¤±è´¥: {str(e)}")
    
    else:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ ¼å¼: {request.format}")


# ========== å‘å¸ƒ API ==========

class CreatePublishRequest(BaseModel):
    """åˆ›å»ºå‘å¸ƒè‰ç¨¿è¯·æ±‚"""
    topic: str
    summary: str = ""
    key_findings: list[str] = []
    sections: list[dict] = []
    notes: list[dict] = []


class UpdatePublishRequest(BaseModel):
    """æ›´æ–°å‘å¸ƒè‰ç¨¿è¯·æ±‚"""
    title: str = None
    content: str = None
    tags: list[str] = None
    cover_image: str = None
    section_images: list[str] = None


@app.post("/api/publish/create")
async def create_publish_draft(request: CreatePublishRequest):
    """åˆ›å»ºå‘å¸ƒè‰ç¨¿"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    draft = service.create_draft(
        topic=request.topic,
        summary=request.summary,
        key_findings=request.key_findings,
        sections=request.sections,
        notes=request.notes
    )
    
    return {
        "success": True,
        "data": draft.model_dump()
    }


@app.get("/api/publish/{draft_id}")
async def get_publish_draft(draft_id: str):
    """è·å–å‘å¸ƒè‰ç¨¿"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    draft = service.get_draft(draft_id)
    
    if not draft:
        raise HTTPException(status_code=404, detail="è‰ç¨¿ä¸å­˜åœ¨")
    
    return {
        "success": True,
        "data": draft.model_dump()
    }


@app.put("/api/publish/{draft_id}")
async def update_publish_draft(draft_id: str, request: UpdatePublishRequest):
    """æ›´æ–°å‘å¸ƒè‰ç¨¿"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    
    updates = {}
    if request.title is not None:
        updates["title"] = request.title[:20]  # é™åˆ¶20å­—
    if request.content is not None:
        updates["content"] = request.content[:200]  # é™åˆ¶200å­—
    if request.tags is not None:
        updates["tags"] = request.tags[:8]
    if request.cover_image is not None:
        updates["cover_image"] = request.cover_image
    if request.section_images is not None:
        updates["section_images"] = request.section_images
    
    draft = service.update_draft(draft_id, updates)
    
    if not draft:
        raise HTTPException(status_code=404, detail="è‰ç¨¿ä¸å­˜åœ¨")
    
    return {
        "success": True,
        "data": draft.model_dump()
    }


@app.delete("/api/publish/{draft_id}")
async def delete_publish_draft(draft_id: str):
    """åˆ é™¤å‘å¸ƒè‰ç¨¿"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    
    if service.delete_draft(draft_id):
        return {"success": True, "message": "å·²åˆ é™¤"}
    
    raise HTTPException(status_code=404, detail="è‰ç¨¿ä¸å­˜åœ¨")


@app.get("/api/publish")
async def list_publish_drafts(limit: int = Query(20, ge=1, le=50)):
    """åˆ—å‡ºæ‰€æœ‰å‘å¸ƒè‰ç¨¿"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    drafts = service.list_drafts(limit=limit)
    
    return {
        "success": True,
        "data": [d.model_dump() for d in drafts]
    }


@app.post("/api/publish/{draft_id}/generate-images")
async def generate_publish_images(draft_id: str):
    """
    SSE: ç”Ÿæˆå‘å¸ƒå›¾ç‰‡ï¼ˆå°é¢+ç« èŠ‚å›¾ï¼‰
    
    è¿”å›å®æ—¶è¿›åº¦æ—¥å¿—
    """
    import json
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    draft = service.get_draft(draft_id)
    
    if not draft:
        raise HTTPException(status_code=404, detail="è‰ç¨¿ä¸å­˜åœ¨")
    
    async def event_generator():
        logs = []
        
        def on_log(msg: str):
            logs.append(msg)
        
        try:
            # å‘é€å¼€å§‹æ¶ˆæ¯
            yield {"data": json.dumps({
                "type": "start",
                "message": "å¼€å§‹ç”Ÿæˆå›¾ç‰‡..."
            }, ensure_ascii=False)}
            
            # å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡
            async def generate_with_logs():
                nonlocal logs
                await service.generate_images(draft_id, on_log=on_log)
            
            # å¯åŠ¨ç”Ÿæˆä»»åŠ¡
            task = asyncio.create_task(generate_with_logs())
            
            # å®šæœŸå‘é€æ—¥å¿—
            last_log_count = 0
            while not task.done():
                await asyncio.sleep(0.5)
                
                # å‘é€æ–°å¢æ—¥å¿—
                if len(logs) > last_log_count:
                    for log in logs[last_log_count:]:
                        yield {"data": json.dumps({
                            "type": "log",
                            "message": log
                        }, ensure_ascii=False)}
                    last_log_count = len(logs)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            await task
            
            # å‘é€å‰©ä½™æ—¥å¿—
            for log in logs[last_log_count:]:
                yield {"data": json.dumps({
                    "type": "log",
                    "message": log
                }, ensure_ascii=False)}
            
            # è·å–æœ€æ–°è‰ç¨¿
            updated_draft = service.get_draft(draft_id)
            
            yield {"data": json.dumps({
                "type": "complete",
                "data": updated_draft.model_dump() if updated_draft else {}
            }, ensure_ascii=False)}
            
        except Exception as e:
            yield {"data": json.dumps({
                "type": "error",
                "message": str(e)
            }, ensure_ascii=False)}
    
    return EventSourceResponse(event_generator())


@app.post("/api/publish/{draft_id}/execute")
async def execute_publish(draft_id: str):
    """
    SSE: æ‰§è¡Œå‘å¸ƒåˆ°å°çº¢ä¹¦
    
    è¿”å›å®æ—¶è¿›åº¦æ—¥å¿—
    """
    import json
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    draft = service.get_draft(draft_id)
    
    if not draft:
        raise HTTPException(status_code=404, detail="è‰ç¨¿ä¸å­˜åœ¨")
    
    async def event_generator():
        logs = []
        
        def on_log(msg: str):
            logs.append(msg)
        
        try:
            yield {"data": json.dumps({
                "type": "start",
                "message": "å¼€å§‹å‘å¸ƒ..."
            }, ensure_ascii=False)}
            
            # æ‰§è¡Œå‘å¸ƒ
            updated_draft = await service.publish(draft_id, on_log=on_log)
            
            # å‘é€æ‰€æœ‰æ—¥å¿—
            for log in logs:
                yield {"data": json.dumps({
                    "type": "log",
                    "message": log
                }, ensure_ascii=False)}
            
            yield {"data": json.dumps({
                "type": "complete",
                "success": updated_draft.status == "published",
                "data": updated_draft.model_dump()
            }, ensure_ascii=False)}
            
        except Exception as e:
            yield {"data": json.dumps({
                "type": "error",
                "message": str(e)
            }, ensure_ascii=False)}
    
    return EventSourceResponse(event_generator())


@app.get("/api/publish/{draft_id}/images/{image_name}")
async def serve_publish_image(draft_id: str, image_name: str):
    """æä¾›å‘å¸ƒå›¾ç‰‡è®¿é—®"""
    from ..services.publisher import get_publish_service
    
    service = get_publish_service()
    draft_dir = service._get_draft_dir(draft_id)
    image_path = os.path.join(draft_dir, "images", image_name)
    
    if not os.path.exists(image_path):
        raise HTTPException(status_code=404, detail="å›¾ç‰‡ä¸å­˜åœ¨")
    
    return FileResponse(image_path)


# ============ è®¾ç½®ç›¸å…³ API ============

def get_effective_config() -> Config:
    """
    è·å–æœ‰æ•ˆé…ç½®ï¼ˆUI è®¾ç½®ä¼˜å…ˆï¼Œç„¶å ENVï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1. UI è®¾ç½®ï¼ˆå¦‚æœé…ç½®äº† API Keyï¼‰
    2. ç¯å¢ƒå˜é‡é…ç½®
    """
    config = Config.from_env()
    ui_settings = get_settings_service().load()
    
    # UI è®¾ç½®è¦†ç›– ENVï¼ˆå¦‚æœ UI è®¾ç½®äº† API Keyï¼‰
    if ui_settings.llm.api_key:
        config.llm.api_key = ui_settings.llm.api_key
        config.llm.base_url = ui_settings.llm.base_url
        config.llm.model = ui_settings.llm.model
    
    return config


@app.get("/api/settings")
async def get_settings():
    """è·å–è„±æ•åçš„è®¾ç½®"""
    return get_settings_service().get_masked()


class SettingsUpdateRequest(BaseModel):
    """è®¾ç½®æ›´æ–°è¯·æ±‚"""
    llm: dict = {}
    vlm: dict = {}
    imageGen: dict = {}


@app.post("/api/settings")
async def save_settings(data: SettingsUpdateRequest):
    """ä¿å­˜è®¾ç½®"""
    from ..services.settings import LLMSettings, VLMSettings, ImageGenSettings
    
    # è½¬æ¢å­—æ®µåï¼ˆå‰ç«¯ä½¿ç”¨ camelCaseï¼Œåç«¯ä½¿ç”¨ snake_caseï¼‰
    llm_data = {
        "api_key": data.llm.get("apiKey", ""),
        "base_url": data.llm.get("baseUrl", "https://api-inference.modelscope.cn/v1"),
        "model": data.llm.get("model", "")
    }
    vlm_data = {
        "enabled": data.vlm.get("enabled", False),
        "api_key": data.vlm.get("apiKey", ""),
        "base_url": data.vlm.get("baseUrl", ""),
        "model": data.vlm.get("model", ""),
        "rate_limit_mode": data.vlm.get("rateLimitMode", True)
    }
    image_gen_data = {
        "enabled": data.imageGen.get("enabled", False),
        "api_key": data.imageGen.get("apiKey", ""),
        "base_url": data.imageGen.get("baseUrl", ""),
        "model": data.imageGen.get("model", ""),
        "rate_limit_mode": data.imageGen.get("rateLimitMode", True)
    }
    
    settings = Settings(
        llm=LLMSettings(**llm_data),
        vlm=VLMSettings(**vlm_data),
        imageGen=ImageGenSettings(**image_gen_data)
    )
    get_settings_service().save(settings)
    return {"success": True, "message": "è®¾ç½®å·²ä¿å­˜"}


class LLMTestRequest(BaseModel):
    """LLM è¿æ¥æµ‹è¯•è¯·æ±‚"""
    apiKey: str
    baseUrl: str
    model: str


@app.post("/api/settings/test")
async def test_llm_connection(data: LLMTestRequest):
    """æµ‹è¯• LLM è¿æ¥"""
    from openai import AsyncOpenAI
    
    try:
        client = AsyncOpenAI(
            api_key=data.apiKey,
            base_url=data.baseUrl
        )
        response = await client.chat.completions.create(
            model=data.model,
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=5
        )
        return {
            "success": True, 
            "message": f"è¿æ¥æˆåŠŸï¼æ¨¡å‹: {response.model}"
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


# ========== SPA è·¯ç”±ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ API è·¯ç”±ä¹‹åæ³¨å†Œï¼‰==========

_static_dir = Path(__file__).parent / "static"
if _static_dir.exists() and (_static_dir / "index.html").exists():
    @app.get("/{full_path:path}", include_in_schema=False)
    async def serve_spa(full_path: str):
        """SPA å…œåº•è·¯ç”±ï¼šè¿”å› index.html æˆ–é™æ€æ–‡ä»¶"""
        # API è·¯ç”±ä¸å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µä¸‹ä¸ä¼šåˆ°è¿™é‡Œï¼Œå› ä¸º API è·¯ç”±å·²å…ˆæ³¨å†Œï¼‰
        if full_path.startswith("api/"):
            raise HTTPException(status_code=404, detail="API not found")
        
        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚é™æ€æ–‡ä»¶
        requested_file = _static_dir / full_path
        if requested_file.exists() and requested_file.is_file():
            return FileResponse(str(requested_file))
        
        # å…¶ä»–æ‰€æœ‰è¯·æ±‚è¿”å› index.htmlï¼ˆSPA è·¯ç”±ï¼‰
        return FileResponse(str(_static_dir / "index.html"))


# ç›´æ¥è¿è¡Œå…¥å£
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
