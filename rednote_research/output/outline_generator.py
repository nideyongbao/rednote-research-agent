"""å¤§çº²ç”Ÿæˆå™¨ - å°†åˆ†æç»“æœè½¬æ¢ä¸ºç»“æ„åŒ–å¤§çº²"""

import json
from typing import Optional, Callable
from openai import AsyncOpenAI
from ..state import ResearchState


OUTLINE_GENERATOR_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç»“æ„åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç ”ç©¶åˆ†æç»“æœè½¬æ¢ä¸ºç»“æ„åŒ–çš„æŠ¥å‘Šå¤§çº²ã€‚

## è¾“å…¥
- ç ”ç©¶ä¸»é¢˜
- åˆ†ææ´å¯Ÿï¼ˆkey_findings, user_pain_points, recommendationsï¼‰
- ç¬”è®°æ•°æ®ï¼ˆæ ‡é¢˜ã€å†…å®¹ã€å›¾ç‰‡ï¼‰
- å¯ç”¨å›¾ç‰‡ç»Ÿè®¡

## è¾“å‡ºè¦æ±‚
ç”Ÿæˆä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªç« èŠ‚ï¼š
```json
[
  {
    "type": "cover",
    "title": "å°é¢æ ‡é¢˜",
    "content": "æŠ¥å‘Šä¸»é¢˜æè¿°",
    "source_notes": [],
    "required_image_keywords": [],
    "preferred_scene_types": []
  },
  {
    "type": "content",
    "title": "ç« èŠ‚æ ‡é¢˜",
    "content": "ç« èŠ‚å†…å®¹ï¼ˆä½¿ç”¨ Markdown æ ¼å¼ï¼‰",
    "source_notes": [0, 2, 5],
    "required_image_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
    "preferred_scene_types": ["åœºæ™¯ç±»å‹"]
  },
  {
    "type": "summary",
    "title": "æ€»ç»“ä¸å»ºè®®",
    "content": "æ€»ç»“å†…å®¹",
    "source_notes": [],
    "required_image_keywords": [],
    "preferred_scene_types": []
  }
]
```

## å›¾ç‰‡éœ€æ±‚å­—æ®µè¯´æ˜
- **required_image_keywords**: è¯¥ç« èŠ‚é…å›¾åº”åŒ…å«çš„å…³é”®è¯ï¼ˆ3-5ä¸ªï¼‰ï¼Œç”¨äºåŒ¹é…å›¾ç‰‡
  - ä¾‹å¦‚ï¼šé¢„ç®—ç« èŠ‚ â†’ ["é¢„ç®—è¡¨", "è´¹ç”¨æ¸…å•", "ä»·æ ¼å¯¹æ¯”"]
  - ä¾‹å¦‚ï¼šé£æ ¼ç« èŠ‚ â†’ ["åŒ—æ¬§é£", "ç°ä»£ç®€çº¦", "æ•ˆæœå›¾"]
- **preferred_scene_types**: åå¥½çš„å›¾ç‰‡åœºæ™¯ç±»å‹ï¼ˆ1-2ä¸ªï¼‰
  - å¯é€‰å€¼ï¼šé£æ ¼å±•ç¤ºã€æ•°æ®å±•ç¤ºã€æ•™ç¨‹æ­¥éª¤ã€äº§å“å±•ç¤ºã€çœŸå®åœºæ™¯

## ç»“æ„åŒ–åŸåˆ™
1. **å°é¢**ï¼šåŒ…å«ä¸»é¢˜å’ŒåŸºäºç¬”è®°æ•°é‡çš„æè¿°
2. **æ ¸å¿ƒå‘ç°**ï¼šå°† key_findings æ•´ç†ä¸ºä¸€ä¸ªç« èŠ‚ï¼Œå…³è”æ”¯æŒè¿™äº›å‘ç°çš„ç¬”è®°
3. **ç”¨æˆ·ç—›ç‚¹**ï¼šå¦‚æœæœ‰ user_pain_pointsï¼Œæ•´ç†ä¸ºç‹¬ç«‹ç« èŠ‚
4. **è¯¦ç»†åˆ†æ**ï¼šæŒ‰ä¸»é¢˜ç»´åº¦ç»„ç»‡ 2-3 ä¸ªå†…å®¹ç« èŠ‚ï¼Œæ¯ä¸ªç« èŠ‚å…³è”ç›¸å…³ç¬”è®°
5. **å»ºè®®æ€»ç»“**ï¼šå°† recommendations æ•´ç†ä¸ºç»“è®ºç« èŠ‚

## å†…å®¹æ ¼å¼
- ä½¿ç”¨ Markdown æ ¼å¼
- æ¯ä¸ªè®ºç‚¹æ ‡æ³¨æ¥æºï¼ˆæ¥æºï¼šç¬”è®°Xï¼‰
- é€‚å½“ä½¿ç”¨åˆ—è¡¨ã€ç²—ä½“ç­‰æ ¼å¼å¢å¼ºå¯è¯»æ€§

ç›´æ¥è¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"""


class OutlineSection:
    """å¤§çº²ç« èŠ‚æ•°æ®ç»“æ„"""
    
    def __init__(
        self,
        type: str,
        title: str,
        content: str,
        source_notes: list[int] = None,
        images: list[str] = None
    ):
        self.type = type
        self.title = title
        self.content = content
        self.source_notes = source_notes or []
        self.images = images or []
    
    def to_dict(self) -> dict:
        return {
            "type": self.type,
            "title": self.title,
            "content": self.content,
            "source_notes": self.source_notes,
            "images": self.images
        }


class OutlineGenerator:
    """
    å¤§çº²ç”Ÿæˆå™¨
    
    èŒè´£ï¼šå°† Analyzer è¾“å‡ºçš„ insights å’Œç¬”è®°æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–å¤§çº²
    
    è®¾è®¡ç†å¿µï¼š
    1. æŒ‰ä¸»é¢˜/ç»´åº¦ç»„ç»‡å†…å®¹
    2. ä¸ºæ¯ä¸ªç« èŠ‚å…³è”ç›¸å…³ç¬”è®°å’Œå›¾ç‰‡
    3. ç¡®ä¿æ¯ä¸ªè®ºç‚¹éƒ½æœ‰æ•°æ®æ¥æºæ ‡æ³¨
    """
    
    def __init__(self, llm_client: AsyncOpenAI, model: str):
        self.llm = llm_client
        self.model = model
    
    async def generate(
        self, 
        state: ResearchState,
        on_log: Optional[Callable[[str], None]] = None
    ) -> list[dict]:
        """
        ç”Ÿæˆç»“æ„åŒ–å¤§çº²
        
        Args:
            state: åŒ…å« insights, documents å’Œ image_analyses çš„ç ”ç©¶çŠ¶æ€
            on_log: å¯é€‰çš„æ—¥å¿—å›è°ƒ
            
        Returns:
            ç»“æ„åŒ–å¤§çº²åˆ—è¡¨
        """
        if on_log:
            on_log("ğŸ“‘ [OutlineGenerator] å¼€å§‹ç”Ÿæˆç»“æ„åŒ–å¤§çº²...")
        
        # å‡†å¤‡æ•°æ®
        notes_summary = self._prepare_notes_summary(state)
        insights_text = self._format_insights(state.insights)
        image_context = self._prepare_image_context(state)
        
        messages = [
            {"role": "system", "content": OUTLINE_GENERATOR_PROMPT},
            {"role": "user", "content": f"""
## ç ”ç©¶ä¸»é¢˜
{state.task}

## åˆ†ææ´å¯Ÿ
{insights_text}

## å¯ç”¨å›¾ç‰‡ç»Ÿè®¡
{image_context}

## ç¬”è®°æ•°æ®ï¼ˆå…± {len(state.documents)} ç¯‡ï¼‰
{notes_summary}

è¯·ç”Ÿæˆç»“æ„åŒ–å¤§çº²ï¼Œæ ¹æ®å›¾ç‰‡åˆ†å¸ƒåˆç†è§„åˆ’æ¯ç« èŠ‚å»ºè®®é…å›¾æ•°é‡ï¼ˆsuggested_image_countï¼‰å’Œåå¥½ç±»å‹ï¼ˆpreferred_image_typesï¼‰ã€‚
"""}
        ]
        
        try:
            response = await self.llm.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=4000,
                temperature=0.5
            )
            
            content = response.choices[0].message.content or "[]"
            
            # è§£æ JSON
            outline = self._parse_outline(content, state)
            
            if on_log:
                on_log(f"ğŸ“‘ [OutlineGenerator] ç”Ÿæˆäº† {len(outline)} ä¸ªç« èŠ‚")
            
            return outline
            
        except Exception as e:
            if on_log:
                on_log(f"âš  [OutlineGenerator] ç”Ÿæˆå¤±è´¥: {str(e)[:100]}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return self._generate_fallback_outline(state)
    
    def _prepare_notes_summary(self, state: ResearchState) -> str:
        """å‡†å¤‡ç¬”è®°æ‘˜è¦ä¾› LLM åˆ†æ"""
        summaries = []
        
        for i, note in enumerate(state.documents[:15]):
            detail = note.detail
            preview = note.preview
            
            title = detail.title or preview.title
            content = (detail.content or preview.content_preview)[:200]
            images = detail.images[:2] if detail.images else []
            
            summary = f"""
### ç¬”è®° {i}: {title}
- ä½œè€…: {detail.author or preview.author}
- ç‚¹èµ: {detail.likes or preview.likes}
- å†…å®¹: {content}...
- å›¾ç‰‡æ•°é‡: {len(detail.images if detail.images else [])}
"""
            summaries.append(summary)
        
        return "\n".join(summaries)
    
    def _format_insights(self, insights: Optional[dict]) -> str:
        """æ ¼å¼åŒ–åˆ†ææ´å¯Ÿ"""
        if not insights:
            return "æ— åˆ†æç»“æœ"
        
        parts = []
        
        if "key_findings" in insights:
            parts.append("### æ ¸å¿ƒå‘ç°")
            for i, finding in enumerate(insights["key_findings"]):
                parts.append(f"{i+1}. {finding}")
        
        if "user_pain_points" in insights:
            parts.append("\n### ç”¨æˆ·ç—›ç‚¹")
            for point in insights["user_pain_points"]:
                parts.append(f"- {point}")
        
        if "recommendations" in insights:
            parts.append("\n### å»ºè®®")
            for rec in insights["recommendations"]:
                parts.append(f"- {rec}")
        
        return "\n".join(parts)
    
    def _prepare_image_context(self, state: ResearchState) -> str:
        """å‡†å¤‡å›¾ç‰‡ä¸Šä¸‹æ–‡ä¿¡æ¯ä¾›å¤§çº²ç”Ÿæˆå‚è€ƒ"""
        if not state.image_analyses:
            return "æš‚æ— å›¾ç‰‡åˆ†æç»“æœ"
        
        # ç»Ÿè®¡åˆ†ç±»
        categories = {}
        usable_count = 0
        for result in state.image_analyses.values():
            cat = result.category or "æœªåˆ†ç±»"
            categories[cat] = categories.get(cat, 0) + 1
            if result.should_use:
                usable_count += 1
        
        parts = [f"- æ€»å›¾ç‰‡æ•°: {len(state.image_analyses)}"]
        parts.append(f"- å¯ç”¨å›¾ç‰‡: {usable_count}")
        parts.append("- åˆ†ç±»ç»Ÿè®¡:")
        for cat, count in categories.items():
            parts.append(f"  - {cat}: {count}å¼ ")
        
        return "\n".join(parts)
    
    def _parse_outline(self, content: str, state: ResearchState) -> list[dict]:
        """è§£æ LLM è¾“å‡ºçš„ JSON å¤§çº²"""
        try:
            # æ¸…ç† markdown ä»£ç å—æ ‡è®°
            content = content.strip()
            if content.startswith("```"):
                lines = content.split("\n")
                content = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])
            
            # æŸ¥æ‰¾ JSON æ•°ç»„
            json_start = content.find("[")
            json_end = content.rfind("]") + 1
            if json_start >= 0 and json_end > json_start:
                outline_data = json.loads(content[json_start:json_end])
            else:
                return self._generate_fallback_outline(state)
            
            # ä¸ºæ¯ä¸ªç« èŠ‚æ·»åŠ å›¾ç‰‡
            outline = []
            for section in outline_data:
                section_dict = {
                    "type": section.get("type", "content"),
                    "title": section.get("title", ""),
                    "content": section.get("content", ""),
                    "source_notes": section.get("source_notes", []),
                    "images": []
                }
                
                # ä»å¼•ç”¨çš„ç¬”è®°ä¸­æå–å›¾ç‰‡
                for note_idx in section_dict["source_notes"]:
                    if 0 <= note_idx < len(state.documents):
                        note = state.documents[note_idx]
                        if note.detail.images:
                            section_dict["images"].extend(note.detail.images[:2])
                
                # é™åˆ¶æ¯ç« èŠ‚æœ€å¤š 4 å¼ å›¾ç‰‡
                section_dict["images"] = section_dict["images"][:4]
                
                outline.append(section_dict)
            
            return outline
            
        except json.JSONDecodeError:
            return self._generate_fallback_outline(state)
    
    def _generate_fallback_outline(self, state: ResearchState) -> list[dict]:
        """ç”Ÿæˆå¤‡ç”¨å¤§çº²ï¼ˆå½“ LLM å¤±è´¥æ—¶ï¼‰"""
        outline = []
        
        # å°é¢
        outline.append({
            "type": "cover",
            "title": state.task,
            "content": f"# {state.task}\n\nåŸºäº {len(state.documents)} ç¯‡å°çº¢ä¹¦ç¬”è®°çš„æ·±åº¦ç ”ç©¶",
            "source_notes": [],
            "images": []
        })
        
        # æ ¸å¿ƒå‘ç°
        if state.insights and state.insights.get("key_findings"):
            findings = state.insights["key_findings"]
            content = "## æ ¸å¿ƒå‘ç°\n\n"
            for i, f in enumerate(findings):
                content += f"{i+1}. {f}\n"
            
            outline.append({
                "type": "content",
                "title": "æ ¸å¿ƒå‘ç°",
                "content": content,
                "source_notes": list(range(min(3, len(state.documents)))),
                "images": self._collect_images(state, 0, 3)
            })
        
        # ç”¨æˆ·ç—›ç‚¹
        if state.insights and state.insights.get("user_pain_points"):
            points = state.insights["user_pain_points"]
            content = "## ç”¨æˆ·ç—›ç‚¹\n\n"
            for p in points:
                content += f"- {p}\n"
            
            outline.append({
                "type": "content",
                "title": "ç”¨æˆ·ç—›ç‚¹",
                "content": content,
                "source_notes": list(range(3, min(6, len(state.documents)))),
                "images": self._collect_images(state, 3, 6)
            })
        
        # å»ºè®®æ€»ç»“
        if state.insights and state.insights.get("recommendations"):
            recs = state.insights["recommendations"]
            content = "## å»ºè®®ä¸æ€»ç»“\n\n"
            for r in recs:
                content += f"- {r}\n"
            
            outline.append({
                "type": "summary",
                "title": "å»ºè®®ä¸æ€»ç»“",
                "content": content,
                "source_notes": [],
                "images": []
            })
        
        return outline
    
    def _collect_images(self, state: ResearchState, start: int, end: int) -> list[str]:
        """ä»ç¬”è®°ä¸­æ”¶é›†å›¾ç‰‡"""
        images = []
        for i in range(start, min(end, len(state.documents))):
            note = state.documents[i]
            if note.detail.images:
                images.extend(note.detail.images[:2])
        return images[:4]
